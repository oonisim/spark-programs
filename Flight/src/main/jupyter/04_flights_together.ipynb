{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 04\n",
    "Find the passengers who have been on more than N flights together within the range (from,to).\n",
    "\n",
    "## Assumptions\n",
    "1. \"more than 3 flights together\" means 4, 5, ... which is bigger than 3. \n",
    "2. Data is clearned and not errorneous\n",
    "3. Timezone consideration is not required\n",
    "\n",
    "## Approaches\n",
    "\n",
    "1. SQL self join that matches with non-self passengerId that have the same flightId.\n",
    "2. Matrix M<sup>T</sup> * M\n",
    "Self product matrix M<sup>T</sup> * M has diagonal represents the number of flghts of respective passenger, and right top part (row/passenger 1, column/passenger2) represents how many flights passenger2 shares with passenger 1.\n",
    "\n",
    "### TODO\n",
    "Implement a matrix way. \n",
    "\n",
    "## Output\n",
    "\n",
    "To avoid having duplicates, passegner 1 ID < passenger ID 2. For instance there will be no (0, 1, 14) and (1, 0, 14) togeher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSV_DELIMITER = ,\n",
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n",
       "DATE_FORMAT = yyyy-MM-dd\n",
       "FLIGHT_DATE_FROM = 2017-01-01\n",
       "FLIGHT_DATE_TO = 2017-12-31\n",
       "NUM_FLIGHT_TOGETHER = 3\n",
       "RESULT_DIR = results/flightsTogether\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "results/flightsTogether"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val CSV_DELIMITER = \",\"\n",
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\"\n",
    "\n",
    "val DATE_FORMAT = \"yyyy-MM-dd\"\n",
    "val FLIGHT_DATE_FROM = \"2017-01-01\"\n",
    "val FLIGHT_DATE_TO   = \"2017-12-31\"\n",
    "val NUM_FLIGHT_TOGETHER = 3\n",
    "\n",
    "val RESULT_DIR = \"results/flightsTogether\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n",
       "times = ListBuffer()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "clear: ()Unit\n",
       "average: ()Long\n",
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ListBuffer()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "\n",
    "val timing = new StringBuffer\n",
    "val times = new ListBuffer[Long]()\n",
    "\n",
    "def clear(): Unit = {\n",
    "    timing.setLength(0)\n",
    "    times.clear\n",
    "}\n",
    "def average(): Long = {\n",
    "    times.reduce(_+_) / times.length\n",
    "}\n",
    "\n",
    "/**\n",
    "@param label Description about the run\n",
    "@code code to execute\n",
    "@return execution\n",
    "*/\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    times.append(stop - start)\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:62: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save: (df: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save(df: DataFrame) = {\n",
    "    df.coalesce(1)\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightData = [passengerId: int, flightId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Transformations, no action yet\n",
    "val flightData = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM-dd\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../resources/flightData.csv\")\n",
    "    .select(\n",
    "        \"passengerId\",\n",
    "        \"flightId\",\n",
    "        \"date\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queryFlightsTogether = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "WITH\n",
       "    --------------------------------------------------------------------------------\n",
       "    -- Passengers flew more than NUM_FLIGHT_TOGETHER times.\n",
       "    --------------------------------------------------------------------------------\n",
       "    more_than_n_flights AS (\n",
       "        SELECT passengerId\n",
       "        FROM flightData\n",
       "        GROUP BY passengerId\n",
       "        --------------------------------------------------------------------------------\n",
       "        -- \"More than 3\" means 4, 5, 6, ... not including 3.\n",
       "        --------------------------------------------------------------------------------\n",
       "        HAVING count(flightId) > 3\n",
       "        ORDER BY passengerId\n",
       "    )\n",
       "SELECT\n",
       "    f.passengerId AS `Passenger 1 ID`,\n",
       "    s.passengerId AS `Passenger 2 ID`,\n",
       "    count(s.flightId) AS ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val queryFlightsTogether = s\"\"\"\n",
    "WITH \n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers flew more than NUM_FLIGHT_TOGETHER times.\n",
    "    --------------------------------------------------------------------------------\n",
    "    more_than_n_flights AS (\n",
    "        SELECT passengerId\n",
    "        FROM flightData\n",
    "        GROUP BY passengerId\n",
    "        --------------------------------------------------------------------------------\n",
    "        -- \"More than 3\" means 4, 5, 6, ... not including 3.\n",
    "        --------------------------------------------------------------------------------\n",
    "        HAVING count(flightId) > $NUM_FLIGHT_TOGETHER\n",
    "        ORDER BY passengerId\n",
    "    )\n",
    "\n",
    "SELECT \n",
    "    f.passengerId AS `Passenger 1 ID`, \n",
    "    s.passengerId AS `Passenger 2 ID`, \n",
    "    count(s.flightId) AS `Number of flights together`,\n",
    "    '$FLIGHT_DATE_FROM' as From,\n",
    "    '$FLIGHT_DATE_TO' as To\n",
    "FROM\n",
    "    flightData f \n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers more than NUM_FLIGHT_TOGETHER flights\n",
    "    --------------------------------------------------------------------------------\n",
    "    INNER JOIN more_than_n_flights m \n",
    "        ON f.passengerId == m.passengerId\n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers who shared same flights\n",
    "    --------------------------------------------------------------------------------\n",
    "    INNER JOIN flightData s \n",
    "        ON f.flightId == s.flightId\n",
    "WHERE\n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Only have (passenger 1 > passenger 2) to avoid having both (p1, p2) and (p2, p1) \n",
    "    --------------------------------------------------------------------------------\n",
    "    f.passengerId < s.passengerId AND  \n",
    "    f.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT') AND\n",
    "    f.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT') AND\n",
    "    s.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT') AND\n",
    "    s.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT')\n",
    "GROUP BY \n",
    "    f.passengerId, s.passengerId\n",
    "HAVING \n",
    "    count(s.flightId) > $NUM_FLIGHT_TOGETHER\n",
    "ORDER BY \n",
    "    f.passengerId, s.passengerId\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run: (label: String, query: String, repeats: Int, toSave: Boolean)Long\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/**\n",
    "Run the SparkSQL \n",
    "@param label Lable to describe this run\n",
    "@param query SQL \n",
    "@param repeats Number of run\n",
    "@return Average execution time in msec\n",
    "*/\n",
    "def run(label: String, query: String, repeats: Int, toSave: Boolean = false): Long = {\n",
    "    val result = spark\n",
    "        .sql(query)\n",
    "        .sort(\n",
    "            desc(\"Number of flights together\"), \n",
    "            asc(\"Passenger 1 ID\"),\n",
    "            asc(\"Passenger 2 ID\")\n",
    "        )\n",
    "\n",
    "    clear()\n",
    "    for (i <- (0 until repeats)){\n",
    "        timed(\n",
    "            label,\n",
    "            result.show(5)\n",
    "        )\n",
    "        println(timing)\n",
    "        println(s\"Average time $average ms\")\n",
    "    }\n",
    "    println(result.rdd.toDebugString)    \n",
    "\n",
    "    if(toSave) save(result)\n",
    "    average\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (passengerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 2895 ms.\n",
      "\n",
      "Average time 2895 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 2895 ms.\n",
      "Processing Order by (passengerId) took 1925 ms.\n",
      "\n",
      "Average time 2410 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 2895 ms.\n",
      "Processing Order by (passengerId) took 1925 ms.\n",
      "Processing Order by (passengerId) took 1757 ms.\n",
      "\n",
      "Average time 2192 ms\n",
      "(12) MapPartitionsRDD[784] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[783] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[782] at rdd at <console>:93 []\n",
      " |   ShuffledRowRDD[781] at rdd at <console>:93 []\n",
      " +-(12) MapPartitionsRDD[780] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[776] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[775] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[774] at rdd at <console>:93 []\n",
      "    |   *(2) Sort [passengerId#2055 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#2055 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#2055,flightId#2056,date#2059] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[714] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |       CachedPartitions: 12; MemorySize: 513.8 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "    |   MapPartitionsRDD[713] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |   ShuffledRowRDD[712] at run at ThreadPoolExecutor.java:1149 []\n",
      "    +-(1) MapPartitionsRDD[711] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  MapPartitionsRDD[707] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  FileScanRDD[706] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassenger = 2192\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassenger = run(\n",
    "    \"Order by (passengerId)\",\n",
    "    queryFlightsTogether,\n",
    "    3,\n",
    "    true\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (flightId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 4226 ms.\n",
      "\n",
      "Average time 4226 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 4226 ms.\n",
      "Processing Order by (flightId) took 3219 ms.\n",
      "\n",
      "Average time 3722 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 4226 ms.\n",
      "Processing Order by (flightId) took 3219 ms.\n",
      "Processing Order by (flightId) took 3168 ms.\n",
      "\n",
      "Average time 3537 ms\n",
      "(12) MapPartitionsRDD[934] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[933] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[932] at rdd at <console>:93 []\n",
      " |   ShuffledRowRDD[931] at rdd at <console>:93 []\n",
      " +-(12) MapPartitionsRDD[930] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[926] at rdd at <console>:93 []\n",
      "    |   ShuffledRowRDD[925] at rdd at <console>:93 []\n",
      "    +-(12) MapPartitionsRDD[924] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[923] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[922] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[921] at rdd at <console>:93 []\n",
      "       |   *(2) Sort [flightId#2056 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(flightId#2056 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#2055,flightId#2056,date#2059] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[816] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 392.0 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[815] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[814] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[813] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[809] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[808] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderFlight = 3537\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"flightId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderFlight = run(\n",
    "    \"Order by (flightId)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"flightId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 3994 ms.\n",
      "\n",
      "Average time 3994 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 3994 ms.\n",
      "Processing Order by (passengerId, flightId) took 2970 ms.\n",
      "\n",
      "Average time 3482 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 3994 ms.\n",
      "Processing Order by (passengerId, flightId) took 2970 ms.\n",
      "Processing Order by (passengerId, flightId) took 3022 ms.\n",
      "\n",
      "Average time 3328 ms\n",
      "(12) MapPartitionsRDD[1061] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1060] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1059] at rdd at <console>:93 []\n",
      " |   ShuffledRowRDD[1058] at rdd at <console>:93 []\n",
      " +-(12) MapPartitionsRDD[1057] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[1053] at rdd at <console>:93 []\n",
      "    |   ShuffledRowRDD[1052] at rdd at <console>:93 []\n",
      "    +-(12) MapPartitionsRDD[1051] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1050] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1049] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1048] at rdd at <console>:93 []\n",
      "       |   *(2) Sort [passengerId#2055 ASC NULLS FIRST, flightId#2056 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#2055 ASC NULLS FIRST, flightId#2056 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#2055,flightId#2056,date#2059] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[943] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 513.8 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[942] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[941] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[940] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[936] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[935] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassengerFlight = 3328\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"flightId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassengerFlight= run(\n",
    "    \"Order by (passengerId, flightId)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"date\")Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4033 ms.\n",
      "\n",
      "Average time 4033 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4033 ms.\n",
      "Processing Order by (passengerId, date) took 2872 ms.\n",
      "\n",
      "Average time 3452 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4033 ms.\n",
      "Processing Order by (passengerId, date) took 2872 ms.\n",
      "Processing Order by (passengerId, date) took 2934 ms.\n",
      "\n",
      "Average time 3279 ms\n",
      "(12) MapPartitionsRDD[1188] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1187] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1186] at rdd at <console>:93 []\n",
      " |   ShuffledRowRDD[1185] at rdd at <console>:93 []\n",
      " +-(12) MapPartitionsRDD[1184] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[1180] at rdd at <console>:93 []\n",
      "    |   ShuffledRowRDD[1179] at rdd at <console>:93 []\n",
      "    +-(12) MapPartitionsRDD[1178] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1177] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1176] at rdd at <console>:93 []\n",
      "       |   MapPartitionsRDD[1175] at rdd at <console>:93 []\n",
      "       |   *(2) Sort [passengerId#2055 ASC NULLS FIRST, date#2059 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#2055 ASC NULLS FIRST, date#2059 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#2055,flightId#2056,date#2059] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[1070] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 514.2 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[1069] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[1068] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[1067] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[1063] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[1062] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassengerDate = 3279\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"date\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassengerDate = run(\n",
    "    \"Order by (passengerId, date)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by none took 3947 ms.\n",
      "\n",
      "Average time 3947 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by none took 3947 ms.\n",
      "Processing Order by none took 3041 ms.\n",
      "\n",
      "Average time 3494 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "|          2939|          5490|                        13|2017-01-01|2017-12-31|\n",
      "|           366|           374|                        12|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by none took 3947 ms.\n",
      "Processing Order by none took 3041 ms.\n",
      "Processing Order by none took 3104 ms.\n",
      "\n",
      "Average time 3364 ms\n",
      "(12) MapPartitionsRDD[1309] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1308] at rdd at <console>:93 []\n",
      " |   MapPartitionsRDD[1307] at rdd at <console>:93 []\n",
      " |   ShuffledRowRDD[1306] at rdd at <console>:93 []\n",
      " +-(12) MapPartitionsRDD[1305] at rdd at <console>:93 []\n",
      "    |   MapPartitionsRDD[1301] at rdd at <console>:93 []\n",
      "    |   ShuffledRowRDD[1300] at rdd at <console>:93 []\n",
      "    +-(1) MapPartitionsRDD[1299] at rdd at <console>:93 []\n",
      "       |  MapPartitionsRDD[1298] at rdd at <console>:93 []\n",
      "       |  MapPartitionsRDD[1297] at rdd at <console>:93 []\n",
      "       |  MapPartitionsRDD[1296] at rdd at <console>:93 []\n",
      "       |  *(1) FileScan csv [passengerId#2055,flightId#2056,date#2059] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[1191] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |      CachedPartitions: 1; MemorySize: 389.6 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |  MapPartitionsRDD[1190] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  FileScanRDD[1189] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderNone = 3364\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderNone = run(\n",
    "    \"Order by none\",\n",
    "    queryFlightsTogether,\n",
    "    3,\n",
    "    true\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elepased Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Order by:\n",
      "(passengerId)           is 2192 ms\n",
      "(flightId)              is 3537 ms\n",
      "(passengerId, date)     is 3279 ms\n",
      "(passengerId, flightId) is 3328 ms\n",
      "Non                     is 3364 ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "report = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "Order by:\n",
       "(passengerId)           is 2192 ms\n",
       "(flightId)              is 3537 ms\n",
       "(passengerId, date)     is 3279 ms\n",
       "(passengerId, flightId) is 3328 ms\n",
       "Non                     is 3364 ms\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val report = s\"\"\"\n",
    "Order by:\n",
    "(passengerId)           is $timeOrderPassenger ms\n",
    "(flightId)              is $timeOrderFlight ms\n",
    "(passengerId, date)     is $timeOrderPassengerDate ms\n",
    "(passengerId, flightId) is $timeOrderPassengerFlight ms\n",
    "Non                     is $timeOrderNone ms\n",
    "\"\"\"\n",
    "println(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|passengerId|count|\n",
      "+-----------+-----+\n",
      "|          1|    5|\n",
      "|         37|    4|\n",
      "|         38|    4|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+--------+\n",
      "|passengerId|flightId|\n",
      "+-----------+--------+\n",
      "|          1|       0|\n",
      "|          1|     972|\n",
      "|          1|     901|\n",
      "|          1|     993|\n",
      "|          1|     940|\n",
      "|         37|     972|\n",
      "|         37|       0|\n",
      "|         37|     940|\n",
      "|         37|     901|\n",
      "|         38|       0|\n",
      "|         38|     901|\n",
      "|         38|     940|\n",
      "|         38|     972|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "query = \n",
       "query = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT passengerId, flightId\n",
       "FROM flightData\n",
       "WHERE passengerId in (1, 37, 38)\n",
       "ORDER BY passengerId\n",
       "\"\n",
       "SELECT passengerId, flightId\n",
       "FROM flightData\n",
       "WHERE passengerId in (1, 37, 38)\n",
       "ORDER BY passengerId\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var query = \n",
    "s\"\"\"\n",
    "SELECT passengerId, count(flightId) as count\n",
    "FROM flightData\n",
    "WHERE passengerId in (1, 37, 38)\n",
    "GROUP BY passengerId\n",
    "HAVING count(flightId) > $NUM_FLIGHT_TOGETHER\n",
    "ORDER BY passengerId\n",
    "\"\"\"\n",
    "spark.sql(query)\n",
    ".show()\n",
    "\n",
    "query = \n",
    "s\"\"\"\n",
    "SELECT passengerId, flightId\n",
    "FROM flightData\n",
    "WHERE passengerId in (1, 37, 38)\n",
    "ORDER BY passengerId\n",
    "\"\"\"\n",
    "spark.sql(query)\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|          2658|                         4|2017-01-01|2017-12-31|\n",
      "|            18|          7558|                         4|2017-01-01|2017-12-31|\n",
      "|            18|         13874|                         4|2017-01-01|2017-12-31|\n",
      "|            56|           169|                         5|2017-01-01|2017-12-31|\n",
      "|            56|          2477|                         4|2017-01-01|2017-12-31|\n",
      "|            58|          3087|                         4|2017-01-01|2017-12-31|\n",
      "|            68|            69|                         4|2017-01-01|2017-12-31|\n",
      "|            95|          4550|                         4|2017-01-01|2017-12-31|\n",
      "|           119|         11034|                         4|2017-01-01|2017-12-31|\n",
      "|           126|           755|                         4|2017-01-01|2017-12-31|\n",
      "|           126|          2325|                         6|2017-01-01|2017-12-31|\n",
      "|           126|          6975|                         4|2017-01-01|2017-12-31|\n",
      "|           130|          3654|                         5|2017-01-01|2017-12-31|\n",
      "|           134|         11214|                         4|2017-01-01|2017-12-31|\n",
      "|           139|          1539|                         5|2017-01-01|2017-12-31|\n",
      "|           142|          5216|                         4|2017-01-01|2017-12-31|\n",
      "|           147|          3920|                         5|2017-01-01|2017-12-31|\n",
      "|           148|          9066|                         5|2017-01-01|2017-12-31|\n",
      "|           157|          5866|                         4|2017-01-01|2017-12-31|\n",
      "|           167|          1097|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seed = 42\n",
       "withReplacement = false\n",
       "fraction = 0.01\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 42\n",
    "val withReplacement = false\n",
    "val fraction = 0.01\n",
    "spark.sql(queryFlightsTogether)\n",
    "    .sample(withReplacement, fraction, seed)\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|            58|          1381|                         7|2017-01-01|2017-12-31|\n",
      "|            58|          2942|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filter01 = (Passenger 2 ID = 2942)\n",
       "filter02 = (Passenger 2 ID = 1381)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<console>:64: warning: a pure expression does nothing in statement position; you may be omitting necessary parentheses\n",
       "\"\"\"\n",
       "^\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Passenger 2 ID = 1381)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "comm -12 \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^1381,/{print $2}' | sort ) \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^58,/{print $2}' | sort)\n",
    "\n",
    "131\n",
    "189\n",
    "217\n",
    "247\n",
    "272\n",
    "283\n",
    "331\n",
    "\n",
    "comm -12 \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^58,/{print $2}' | sort ) \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^2942,/{print $2}' | sort)\n",
    "\n",
    "131\n",
    "189\n",
    "217\n",
    "247\n",
    "$ comm -12 \\\n",
    "> <(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^701,/{print $2}' | sort ) \\\n",
    "> <(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^760,/{print $2}' | sort)\n",
    "13\n",
    "18\n",
    "333\n",
    "34\n",
    "361\n",
    "374\n",
    "391\n",
    "404\n",
    "432\n",
    "45\n",
    "58\n",
    "7\n",
    "77\n",
    "91\n",
    "96\n",
    "\"\"\"\n",
    "\n",
    "val filter01 = col(\"Passenger 2 ID\") === 2942\n",
    "val filter02 = col(\"Passenger 2 ID\") === 1381\n",
    "spark.sql(queryFlightsTogether)\n",
    "    .where(col(\"Passenger 1 ID\") === 58)\n",
    "    .where(filter01.or(filter02))\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
