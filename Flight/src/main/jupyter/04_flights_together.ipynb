{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 04\n",
    "Find the passengers who have been on more than N flights together within the range (from,to).\n",
    "\n",
    "## Assumptions\n",
    "1. \"more than 3 flights together\" means 4, 5, ... which is bigger than 3. \n",
    "2. Data is clearned and not errorneous\n",
    "3. Timezone consideration is not required\n",
    "\n",
    "## Approaches\n",
    "\n",
    "1. SQL self join that matches with non-self passengerId that have the same flightId.\n",
    "2. Matrix M * M<sup>T</sup>\n",
    "Self product matrix Matrix M * M<sup>T</sup> has diagonal represents the number of flghts of respective passenger, and right top part (row/passenger 1, column/passenger2) represents how many flights passenger2 shares with passenger 1.\n",
    "\n",
    "### TODO\n",
    "Implement a matrix way. \n",
    "\n",
    "## Output\n",
    "\n",
    "To avoid having duplicates, passegner 1 ID < passenger ID 2. For instance there will be no (0, 1, 14) and (1, 0, 14) togeher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSV_DELIMITER = ,\n",
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n",
       "DATE_FORMAT = yyyy-MM-dd\n",
       "FLIGHT_DATE_FROM = 2017-01-01\n",
       "FLIGHT_DATE_TO = 2017-12-31\n",
       "NUM_FLIGHT_TOGETHER = 3\n",
       "RESULT_DIR = results/flightsTogether\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "results/flightsTogether"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val CSV_DELIMITER = \",\"\n",
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\"\n",
    "\n",
    "val DATE_FORMAT = \"yyyy-MM-dd\"\n",
    "val FLIGHT_DATE_FROM = \"2017-01-01\"\n",
    "val FLIGHT_DATE_TO   = \"2017-12-31\"\n",
    "val NUM_FLIGHT_TOGETHER = 3\n",
    "\n",
    "val RESULT_DIR = \"results/flightsTogether\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n",
       "times = ListBuffer()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "clear: ()Unit\n",
       "average: ()Long\n",
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ListBuffer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "\n",
    "val timing = new StringBuffer\n",
    "val times = new ListBuffer[Long]()\n",
    "\n",
    "def clear(): Unit = {\n",
    "    timing.setLength(0)\n",
    "    times.clear\n",
    "}\n",
    "def average(): Long = {\n",
    "    times.reduce(_+_) / times.length\n",
    "}\n",
    "\n",
    "/**\n",
    "@param label Description about the run\n",
    "@code code to execute\n",
    "@return execution\n",
    "*/\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    times.append(stop - start)\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:45: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save: (df: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save(df: DataFrame) = {\n",
    "    df.coalesce(1)\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightData = [passengerId: int, flightId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Transformations, no action yet\n",
    "val flightData = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM-dd\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../resources/flightData.csv\")\n",
    "    .select(\n",
    "        \"passengerId\",\n",
    "        \"flightId\",\n",
    "        \"date\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queryFlightsTogether = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "WITH\n",
       "    --------------------------------------------------------------------------------\n",
       "    -- Passengers flew more than NUM_FLIGHT_TOGETHER times.\n",
       "    --------------------------------------------------------------------------------\n",
       "    more_than_n_flights AS (\n",
       "        SELECT passengerId\n",
       "        FROM flightData\n",
       "        GROUP BY passengerId\n",
       "        --------------------------------------------------------------------------------\n",
       "        -- \"More than 3\" means 4, 5, 6, ... not including 3.\n",
       "        --------------------------------------------------------------------------------\n",
       "        HAVING count(flightId) > 3\n",
       "        ORDER BY passengerId\n",
       "    )\n",
       "SELECT\n",
       "    f.passengerId AS `Passenger 1 ID`,\n",
       "    s.passengerId AS `Passenger 2 ID`,\n",
       "    count(s.flightId) AS ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val queryFlightsTogether = s\"\"\"\n",
    "WITH \n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers flew more than NUM_FLIGHT_TOGETHER times.\n",
    "    --------------------------------------------------------------------------------\n",
    "    more_than_n_flights AS (\n",
    "        SELECT passengerId\n",
    "        FROM flightData\n",
    "        GROUP BY passengerId\n",
    "        --------------------------------------------------------------------------------\n",
    "        -- \"More than 3\" means 4, 5, 6, ... not including 3.\n",
    "        --------------------------------------------------------------------------------\n",
    "        HAVING count(flightId) > $NUM_FLIGHT_TOGETHER\n",
    "        ORDER BY passengerId\n",
    "    )\n",
    "\n",
    "SELECT \n",
    "    f.passengerId AS `Passenger 1 ID`, \n",
    "    s.passengerId AS `Passenger 2 ID`, \n",
    "    count(s.flightId) AS `Number of flights together`,\n",
    "    '$FLIGHT_DATE_FROM' as From,\n",
    "    '$FLIGHT_DATE_TO' as To\n",
    "FROM\n",
    "    flightData f \n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers more than NUM_FLIGHT_TOGETHER flights\n",
    "    --------------------------------------------------------------------------------\n",
    "    INNER JOIN more_than_n_flights m \n",
    "        ON f.passengerId == m.passengerId\n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Passengers who shared same flights\n",
    "    --------------------------------------------------------------------------------\n",
    "    INNER JOIN flightData s \n",
    "        ON f.flightId == s.flightId\n",
    "WHERE\n",
    "    --------------------------------------------------------------------------------\n",
    "    -- Only have (passenger 1 > passenger 2) to avoid having both (p1, p2) and (p2, p1) \n",
    "    --------------------------------------------------------------------------------\n",
    "    f.passengerId < s.passengerId AND  \n",
    "    f.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT') AND\n",
    "    f.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT') AND\n",
    "    s.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT') AND\n",
    "    s.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT')\n",
    "GROUP BY \n",
    "    f.passengerId, s.passengerId\n",
    "HAVING \n",
    "    count(s.flightId) > $NUM_FLIGHT_TOGETHER\n",
    "--ORDER BY \n",
    "--    `Number of flights together`, \n",
    "--    f.passengerId, \n",
    "--    s.passengerId\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run: (label: String, repeats: Int, toSave: Boolean)Long\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/**\n",
    "Run the SparkSQL \n",
    "@param label Lable to describe this run\n",
    "@param query SQL \n",
    "@param repeats Number of run\n",
    "@return Average execution time in msec\n",
    "*/\n",
    "def run(label: String, repeats: Int, toSave: Boolean = false): Long = {\n",
    "    val result = spark\n",
    "        .sql(queryFlightsTogether)\n",
    "        .sort(\n",
    "//            desc(\"Number of flights together\"), \n",
    "            asc(\"Passenger 1 ID\"),\n",
    "            asc(\"Passenger 2 ID\")\n",
    "        )\n",
    "\n",
    "    clear()\n",
    "    for (i <- (0 until repeats)){\n",
    "        timed(\n",
    "            label,\n",
    "            result.show(3)\n",
    "        )\n",
    "        println(timing)\n",
    "        println(s\"Average time $average ms\")\n",
    "    }\n",
    "    println(result.rdd.toDebugString)    \n",
    "\n",
    "    if(toSave) save(result)\n",
    "    \n",
    "    average\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (passengerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4898 ms.\n",
      "\n",
      "Average time 4898 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4898 ms.\n",
      "Processing Order by (passengerId) took 2043 ms.\n",
      "\n",
      "Average time 3470 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4898 ms.\n",
      "Processing Order by (passengerId) took 2043 ms.\n",
      "Processing Order by (passengerId) took 2158 ms.\n",
      "\n",
      "Average time 3033 ms\n",
      "(12) MapPartitionsRDD[87] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[86] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[85] at rdd at <console>:76 []\n",
      " |   ShuffledRowRDD[84] at rdd at <console>:76 []\n",
      " +-(12) MapPartitionsRDD[83] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[79] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[78] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[77] at rdd at <console>:76 []\n",
      "    |   *(2) Sort [passengerId#10 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[17] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |       CachedPartitions: 12; MemorySize: 513.8 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "    |   MapPartitionsRDD[16] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |   ShuffledRowRDD[15] at run at ThreadPoolExecutor.java:1149 []\n",
      "    +-(1) MapPartitionsRDD[14] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  MapPartitionsRDD[10] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  FileScanRDD[9] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeOrderPassenger = 3033\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "df: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\")\n",
    "    .persist\n",
    "    .createOrReplaceTempView(\"flightData\")\n",
    "\n",
    "val timeOrderPassenger = run(\n",
    "    \"Order by (passengerId)\",\n",
    "    3,\n",
    "    true\n",
    ")\n",
    "spark.catalog.dropTempView(\"flightData\")\n",
    "\n",
    "flightData.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (flightId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (flightId) took 5463 ms.\n",
      "\n",
      "Average time 5463 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (flightId) took 5463 ms.\n",
      "Processing Order by (flightId) took 3412 ms.\n",
      "\n",
      "Average time 4437 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (flightId) took 5463 ms.\n",
      "Processing Order by (flightId) took 3412 ms.\n",
      "Processing Order by (flightId) took 3468 ms.\n",
      "\n",
      "Average time 4114 ms\n",
      "(12) MapPartitionsRDD[237] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[236] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[235] at rdd at <console>:76 []\n",
      " |   ShuffledRowRDD[234] at rdd at <console>:76 []\n",
      " +-(12) MapPartitionsRDD[233] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[229] at rdd at <console>:76 []\n",
      "    |   ShuffledRowRDD[228] at rdd at <console>:76 []\n",
      "    +-(12) MapPartitionsRDD[227] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[226] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[225] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[224] at rdd at <console>:76 []\n",
      "       |   *(2) Sort [flightId#11 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(flightId#11 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[119] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 392.3 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[118] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[117] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[116] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[112] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[111] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeOrderFlight = 4114\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "df: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"flightId\")\n",
    "    .persist\n",
    "    .createOrReplaceTempView(\"flightData\")\n",
    "\n",
    "val timeOrderFlight = run(\n",
    "    \"Order by (flightId)\",\n",
    "    3\n",
    ")\n",
    "\n",
    "spark.catalog.dropTempView(\"flightData\")\n",
    "flightData.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"flightId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 4354 ms.\n",
      "\n",
      "Average time 4354 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 4354 ms.\n",
      "Processing Order by (passengerId, flightId) took 3081 ms.\n",
      "\n",
      "Average time 3717 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 4354 ms.\n",
      "Processing Order by (passengerId, flightId) took 3081 ms.\n",
      "Processing Order by (passengerId, flightId) took 2966 ms.\n",
      "\n",
      "Average time 3467 ms\n",
      "(12) MapPartitionsRDD[364] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[363] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[362] at rdd at <console>:76 []\n",
      " |   ShuffledRowRDD[361] at rdd at <console>:76 []\n",
      " +-(12) MapPartitionsRDD[360] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[356] at rdd at <console>:76 []\n",
      "    |   ShuffledRowRDD[355] at rdd at <console>:76 []\n",
      "    +-(12) MapPartitionsRDD[354] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[353] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[352] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[351] at rdd at <console>:76 []\n",
      "       |   *(2) Sort [passengerId#10 ASC NULLS FIRST, flightId#11 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, flightId#11 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[246] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 513.7 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[245] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[244] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[243] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[239] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[238] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeOrderPassengerFlight = 3467\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "df: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"flightId\")\n",
    "    .persist\n",
    "    .createOrReplaceTempView(\"flightData\")\n",
    "\n",
    "val timeOrderPassengerFlight= run(\n",
    "    \"Order by (passengerId, flightId)\",\n",
    "    3\n",
    ")\n",
    "\n",
    "spark.catalog.dropTempView(\"flightData\")\n",
    "flightData.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"date\")Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4251 ms.\n",
      "\n",
      "Average time 4251 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4251 ms.\n",
      "Processing Order by (passengerId, date) took 3053 ms.\n",
      "\n",
      "Average time 3652 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 4251 ms.\n",
      "Processing Order by (passengerId, date) took 3053 ms.\n",
      "Processing Order by (passengerId, date) took 3024 ms.\n",
      "\n",
      "Average time 3442 ms\n",
      "(12) MapPartitionsRDD[491] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[490] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[489] at rdd at <console>:76 []\n",
      " |   ShuffledRowRDD[488] at rdd at <console>:76 []\n",
      " +-(12) MapPartitionsRDD[487] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[483] at rdd at <console>:76 []\n",
      "    |   ShuffledRowRDD[482] at rdd at <console>:76 []\n",
      "    +-(12) MapPartitionsRDD[481] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[480] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[479] at rdd at <console>:76 []\n",
      "       |   MapPartitionsRDD[478] at rdd at <console>:76 []\n",
      "       |   *(2) Sort [passengerId#10 ASC NULLS FIRST, date#14 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, date#14 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[373] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 513.9 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[372] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[371] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[370] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[366] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[365] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeOrderPassengerDate = 3442\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "df: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"date\")\n",
    "    .persist\n",
    "    .createOrReplaceTempView(\"flightData\")\n",
    "\n",
    "val timeOrderPassengerDate = run(\n",
    "    \"Order by (passengerId, date)\",\n",
    "    3\n",
    ")\n",
    "\n",
    "spark.catalog.dropTempView(\"flightData\")\n",
    "flightData.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by none took 5774 ms.\n",
      "\n",
      "Average time 5774 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by none took 5774 ms.\n",
      "Processing Order by none took 3121 ms.\n",
      "\n",
      "Average time 4447 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|           701|           760|                        15|2017-01-01|2017-12-31|\n",
      "|          2717|          2759|                        14|2017-01-01|2017-12-31|\n",
      "|          3503|          3590|                        14|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Processing Order by none took 5774 ms.\n",
      "Processing Order by none took 3121 ms.\n",
      "Processing Order by none took 3053 ms.\n",
      "\n",
      "Average time 3982 ms\n",
      "(12) MapPartitionsRDD[612] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[611] at rdd at <console>:76 []\n",
      " |   MapPartitionsRDD[610] at rdd at <console>:76 []\n",
      " |   ShuffledRowRDD[609] at rdd at <console>:76 []\n",
      " +-(12) MapPartitionsRDD[608] at rdd at <console>:76 []\n",
      "    |   MapPartitionsRDD[604] at rdd at <console>:76 []\n",
      "    |   ShuffledRowRDD[603] at rdd at <console>:76 []\n",
      "    +-(1) MapPartitionsRDD[602] at rdd at <console>:76 []\n",
      "       |  MapPartitionsRDD[601] at rdd at <console>:76 []\n",
      "       |  MapPartitionsRDD[600] at rdd at <console>:76 []\n",
      "       |  MapPartitionsRDD[599] at rdd at <console>:76 []\n",
      "       |  *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[494] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |      CachedPartitions: 1; MemorySize: 389.6 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |  MapPartitionsRDD[493] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |  FileScanRDD[492] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeOrderNone = 3982\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData\n",
    "    .persist\n",
    "    .createOrReplaceTempView(\"flightData\")\n",
    "\n",
    "val timeOrderNone = run(\n",
    "    \"Order by none\",\n",
    "    3\n",
    ")\n",
    "\n",
    "spark.catalog.dropTempView(\"flightData\")\n",
    "flightData.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elepased Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Order by:\n",
      "Non                     is 3982 ms\n",
      "(passengerId)           is 3052 ms\n",
      "(flightId)              is 4114 ms\n",
      "(passengerId, date)     is 3442 ms\n",
      "(passengerId, flightId) is 3467 ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "report = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "Order by:\n",
       "Non                     is 3982 ms\n",
       "(passengerId)           is 3052 ms\n",
       "(flightId)              is 4114 ms\n",
       "(passengerId, date)     is 3442 ms\n",
       "(passengerId, flightId) is 3467 ms\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val report = s\"\"\"\n",
    "Order by:\n",
    "Non                     is $timeOrderNone ms\n",
    "(passengerId)           is $timeOrderPassenger ms\n",
    "(flightId)              is $timeOrderFlight ms\n",
    "(passengerId, date)     is $timeOrderPassengerDate ms\n",
    "(passengerId, flightId) is $timeOrderPassengerFlight ms\n",
    "\"\"\"\n",
    "println(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData.createOrReplaceTempView(\"flightData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|passengerId|count|\n",
      "+-----------+-----+\n",
      "|          1|    5|\n",
      "|         37|    4|\n",
      "|         38|    4|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+--------+\n",
      "|passengerId|flightId|\n",
      "+-----------+--------+\n",
      "|          1|       0|\n",
      "|          1|     972|\n",
      "|          1|     901|\n",
      "|          1|     993|\n",
      "|          1|     940|\n",
      "|         37|     972|\n",
      "|         37|       0|\n",
      "|         37|     940|\n",
      "|         37|     901|\n",
      "|         38|       0|\n",
      "|         38|     901|\n",
      "|         38|     940|\n",
      "|         38|     972|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "query = \n",
       "query = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT passengerId, flightId\n",
       "FROM flightData\n",
       "WHERE passengerId in (1, 37, 38)\n",
       "ORDER BY passengerId\n",
       "\"\n",
       "SELECT passengerId, flightId\n",
       "FROM flightData\n",
       "WHERE passengerId in (1, 37, 38)\n",
       "ORDER BY passengerId\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var query = \n",
    "s\"\"\"\n",
    "SELECT passengerId, count(flightId) as count\n",
    "FROM flightData\n",
    "WHERE passengerId in (1, 37, 38)\n",
    "GROUP BY passengerId\n",
    "HAVING count(flightId) > $NUM_FLIGHT_TOGETHER\n",
    "ORDER BY passengerId\n",
    "\"\"\"\n",
    "spark.sql(query)\n",
    ".show()\n",
    "\n",
    "query = \n",
    "s\"\"\"\n",
    "SELECT passengerId, flightId\n",
    "FROM flightData\n",
    "WHERE passengerId in (1, 37, 38)\n",
    "ORDER BY passengerId\n",
    "\"\"\"\n",
    "spark.sql(query)\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|           618|           648|                         5|2017-01-01|2017-12-31|\n",
      "|           704|           749|                         5|2017-01-01|2017-12-31|\n",
      "|           712|          1043|                         4|2017-01-01|2017-12-31|\n",
      "|           366|           759|                         6|2017-01-01|2017-12-31|\n",
      "|          1878|          1891|                         5|2017-01-01|2017-12-31|\n",
      "|          2165|          2181|                         4|2017-01-01|2017-12-31|\n",
      "|          3532|          3552|                         4|2017-01-01|2017-12-31|\n",
      "|           246|          3195|                         4|2017-01-01|2017-12-31|\n",
      "|          2510|          3180|                         4|2017-01-01|2017-12-31|\n",
      "|          1693|          2560|                         4|2017-01-01|2017-12-31|\n",
      "|          2699|          3913|                         5|2017-01-01|2017-12-31|\n",
      "|          4260|          4282|                         5|2017-01-01|2017-12-31|\n",
      "|          4329|          4345|                         4|2017-01-01|2017-12-31|\n",
      "|          2223|          3540|                         5|2017-01-01|2017-12-31|\n",
      "|          4617|          4630|                         4|2017-01-01|2017-12-31|\n",
      "|          1844|          2789|                         4|2017-01-01|2017-12-31|\n",
      "|           245|          1755|                         4|2017-01-01|2017-12-31|\n",
      "|          2867|          4083|                         5|2017-01-01|2017-12-31|\n",
      "|          5001|          5098|                         6|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seed = 42\n",
       "withReplacement = false\n",
       "fraction = 0.01\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 42\n",
    "val withReplacement = false\n",
    "val fraction = 0.01\n",
    "spark.sql(queryFlightsTogether)\n",
    "    .sample(withReplacement, fraction, seed)\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|            58|          1381|                         7|2017-01-01|2017-12-31|\n",
      "|            58|          2942|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filter01 = (Passenger 2 ID = 2942)\n",
       "filter02 = (Passenger 2 ID = 1381)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<console>:44: warning: a pure expression does nothing in statement position; you may be omitting necessary parentheses\n",
       "\"\"\"\n",
       "^\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Passenger 2 ID = 1381)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "comm -12 \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^1381,/{print $2}' | sort ) \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^58,/{print $2}' | sort)\n",
    "\n",
    "131\n",
    "189\n",
    "217\n",
    "247\n",
    "272\n",
    "283\n",
    "331\n",
    "\n",
    "comm -12 \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^58,/{print $2}' | sort ) \\\n",
    "<(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^2942,/{print $2}' | sort)\n",
    "\n",
    "131\n",
    "189\n",
    "217\n",
    "247\n",
    "$ comm -12 \\\n",
    "> <(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^701,/{print $2}' | sort ) \\\n",
    "> <(cat ../../../main/resources/flightData.csv | awk '{FS=\",\"} /^760,/{print $2}' | sort)\n",
    "13\n",
    "18\n",
    "333\n",
    "34\n",
    "361\n",
    "374\n",
    "391\n",
    "404\n",
    "432\n",
    "45\n",
    "58\n",
    "7\n",
    "77\n",
    "91\n",
    "96\n",
    "\"\"\"\n",
    "\n",
    "val filter01 = col(\"Passenger 2 ID\") === 2942\n",
    "val filter02 = col(\"Passenger 2 ID\") === 1381\n",
    "spark.sql(queryFlightsTogether)\n",
    "    .where(col(\"Passenger 1 ID\") === 58)\n",
    "    .where(filter01.or(filter02))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------------+----------------+\n",
      "|count(DISTINCT passengerId)|min(passengerId)|max(passengerId)|\n",
      "+---------------------------+----------------+----------------+\n",
      "|                      15500|               1|           15500|\n",
      "+---------------------------+----------------+----------------+\n",
      "\n",
      "+------------------------+-------------+-------------+\n",
      "|count(DISTINCT flightId)|min(flightId)|max(flightId)|\n",
      "+------------------------+-------------+-------------+\n",
      "|                    1000|            0|          999|\n",
      "+------------------------+-------------+-------------+\n",
      "\n",
      "+--------+-----+\n",
      "|flightId|count|\n",
      "+--------+-----+\n",
      "|      14|  100|\n",
      "|      18|  100|\n",
      "|      25|  100|\n",
      "|      38|  100|\n",
      "|      46|  100|\n",
      "|      50|  100|\n",
      "|      73|  100|\n",
      "|      97|  100|\n",
      "|     161|  100|\n",
      "|     172|  100|\n",
      "|     186|  100|\n",
      "|     225|  100|\n",
      "|     232|  100|\n",
      "|     233|  100|\n",
      "|     248|  100|\n",
      "|     254|  100|\n",
      "|     257|  100|\n",
      "|     263|  100|\n",
      "|     280|  100|\n",
      "|     282|  100|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+\n",
      "|total_passengers|\n",
      "+----------------+\n",
      "|          100000|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "queryPassengersPerFlight = \n",
       "totalPassengers = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT flightId, count(passengerId) as count\n",
       "FROM flightData\n",
       "GROUP BY flightId\n",
       "ORDER BY count DESC\n",
       "\"\n",
       "\"\n",
       "SELECT count(passengerId) as total_passengers\n",
       "FROM flightData\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flightData.select(\n",
    "    countDistinct(\"passengerId\"),\n",
    "    min(\"passengerId\"),\n",
    "    max(\"passengerId\")\n",
    ").show\n",
    "\n",
    "flightData.select(\n",
    "    countDistinct(\"flightId\"),\n",
    "    min(\"flightId\"),\n",
    "    max(\"flightId\")\n",
    ").show\n",
    "\n",
    "val queryPassengersPerFlight = \"\"\"\n",
    "SELECT flightId, count(passengerId) as count\n",
    "FROM flightData\n",
    "GROUP BY flightId\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "spark.sql(queryPassengersPerFlight)\n",
    "    .show()\n",
    "\n",
    "val totalPassengers = \"\"\"\n",
    "SELECT count(passengerId) as total_passengers\n",
    "FROM flightData\n",
    "\"\"\"\n",
    "spark.sql(totalPassengers)\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.dropTempView(\"flightData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
