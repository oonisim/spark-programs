{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a609ffd2",
   "metadata": {},
   "source": [
    "# Telco indicent management record\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37098727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fc02f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e765d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda2e06",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42eeab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = !whoami\n",
    "USER = USER[0]\n",
    "\n",
    "PYSPARK_PYTHON_PATH = f\"/home/{USER}/venv/ml/bin/python3\"\n",
    "HADOOP_HOME = \"/opt/hadoop/hadoop-3.2.2\"\n",
    "SPARK_HOME = \"/opt/spark/spark-3.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc892c",
   "metadata": {},
   "source": [
    "#  Environemnt Variables\n",
    "\n",
    "## Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ee72b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/hadoop/hadoop-3.2.2/etc/hadoop'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = f\"{HADOOP_HOME}/etc/hadoop\"\n",
    "os.environ['HADOOP_CONF_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21805809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capacity-scheduler.xml\n",
      "configuration.xsl\n",
      "container-executor.cfg\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$HADOOP_HOME\"\n",
    "export HADOOP_CONF_DIR=\"$1/etc/hadoop\"\n",
    "ls $HADOOP_CONF_DIR | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ea383",
   "metadata": {},
   "source": [
    "## PYTHONPATH\n",
    "\n",
    "Refer to the **pyspark** modules to load from the ```$SPARK_HOME/python/lib``` in the Spark installation.\n",
    "\n",
    "* [PySpark Getting Started](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
    "\n",
    "> Ensure the SPARK_HOME environment variable points to the directory where the tar file has been extracted. Update PYTHONPATH environment variable such that it can find the PySpark and Py4J under SPARK_HOME/python/lib. One example of doing this is shown below:\n",
    "\n",
    "```\n",
    "export PYTHONPATH=$(ZIPS=(\"$SPARK_HOME\"/python/lib/*.zip); IFS=:; echo \"${ZIPS[*]}\"):$PYTHONPATH\n",
    "```\n",
    "\n",
    "Alternatively install **pyspark** with pip or conda locally which installs the Spark runtime libararies (for standalone).\n",
    "\n",
    "* [Can PySpark work without Spark?](https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark)\n",
    "\n",
    "> As of v2.2, executing pip install pyspark will install Spark. If you're going to use Pyspark it's clearly the simplest way to get started. On my system Spark is installed inside my virtual environment (miniconda) at lib/python3.6/site-packages/pyspark/jars  \n",
    "> PySpark has a Spark installation installed. If installed through pip3, you can find it with pip3 show pyspark. Ex. for me it is at ~/.local/lib/python3.8/site-packages/pyspark. This is a standalone configuration so it can't be used for managing clusters like a full Spark installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbbd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTHONPATH'] = \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip:/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "sys.path.extend([\n",
    "    f\"{SPARK_HOME}/python/lib/py4j-0.10.9-src.zip\",\n",
    "    f\"{SPARK_HOME}/python/lib/pyspark.zip\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b9755",
   "metadata": {},
   "source": [
    "## PYSPARK_PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "830da51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = PYSPARK_PYTHON_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe5c58",
   "metadata": {},
   "source": [
    "## JAVA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f18676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318e32e",
   "metadata": {},
   "source": [
    "## PySpark packages\n",
    "\n",
    "Execute after the PYTHONPATH setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b654665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    lit,\n",
    "    when,\n",
    "    isnan,\n",
    "    isnull,\n",
    "    lower,\n",
    "    upper,\n",
    "    regexp_replace,\n",
    "    regexp_extract,\n",
    "    concat,\n",
    "    udf,\n",
    "    array,\n",
    "    avg,\n",
    "    stddev,\n",
    "    to_date,\n",
    "    to_timestamp,\n",
    "    from_unixtime,\n",
    "    year, \n",
    "    month,\n",
    "    months_between,\n",
    "    add_months,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84cdb11",
   "metadata": {},
   "source": [
    "---\n",
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d4da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4882cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 22:44:18,949 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-02-27 22:44:21,777 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# For YARN cluster\n",
    "#    .config('spark.yarn.appMasterEnv.PYSPARK_PYTHON', f\"/home/{USER}/venv/ml/bin/python3\")\\\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.debug.maxToStringFields', 100) \\\n",
    "    .config('spark.executor.memory', '2g') \\\n",
    "    .config('spark.yarn.executorEnv.PYSPARK_PYTHON', f\"/home/{USER}/venv/ml/bin/python3\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc80e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 4\n",
    "NUM_PARTITIONS = 3\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7f35c",
   "metadata": {},
   "source": [
    "---\n",
    "# Data\n",
    "\n",
    "## alarms.json\n",
    "\n",
    "Each tower has sensors to monitor and report issues. When sensor detects an issue, it generates an alarm.\n",
    "\n",
    "#### ALARM_SRC \n",
    "\n",
    "Column ALARM_SRC contains three elements ```(Network, SubNetwork, MeContext)``` of the tower \n",
    "\n",
    "1. Network shows the name of the network and it is a constant i.e. UK_TEL_LON\n",
    "2. SubNetwork shows the tower on which alarm is raised i.e. LON001\n",
    "3. MeContext shows the part of the tower having issue i.e. LON001LTE4813\n",
    "\n",
    "Type of network - ALARM_SRC.MeContext also tells us if the network is 2G, 3G or 4G.\n",
    "* If MeContext contains LTE it is 4G network\n",
    "* If MeContext contains UTM it is 3G network\n",
    "* If MeContext contains GSM it is 2G network\n",
    "\n",
    "Example:\n",
    "```{\"Network\":\"UK_TEL_LON\",\"SubNetwork\":\"LON001\",\"MeContext\":\"LON001LTE4813\"}```\n",
    "\n",
    "\n",
    "## tickets.dat\n",
    "\n",
    "If an alarm requires attention or some type of fix, a ticket is raised for Operations. Then the \"Operation\" team would either resolve it remotely or by visiting the site.\n",
    "\n",
    "## team.csv\n",
    "Details about the team who works on solving the ticket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87c19abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: alarms.json             \n",
      "  inflating: team.csv                \n",
      "  inflating: tickets.dat             \n",
      "total 13288\n",
      "-rw-r--r-- 1 oonisim oonisim 9785106 Feb 27 22:51 alarms.json\n",
      "-rw-rw-r-- 1 oonisim oonisim 1649258 Feb 27 22:52 data.zip\n",
      "-rw-r--r-- 1 oonisim oonisim     159 Feb 27 22:51 team.csv\n",
      "-rw-r--r-- 1 oonisim oonisim 2163571 Feb 27 22:51 tickets.dat\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ./data\n",
    "unzip -o data.zip\n",
    "ls -l \n",
    "\n",
    "hdfs dfs -mkdir -p mc\n",
    "hdfs dfs -put -f team.csv tickets.dat alarms.json mc/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401e322",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270d39e",
   "metadata": {},
   "source": [
    "# Team\n",
    "\n",
    "## team_id column\n",
    "The team.csv has the ```team_id``` column that has **team0NN** format whereas the tickets.csv has the corresponding ```team``` that has **teamNN** format. For instance **team028** in team.csv and **team28** in tickets.csv. Convert the team_id to **teamNN** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d9bec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- team_size: integer (nullable = true)\n",
      " |-- avg_experience_years: integer (nullable = true)\n",
      " |-- team: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+\n",
      "|team_size|avg_experience_years|team  |\n",
      "+---------+--------------------+------+\n",
      "|6        |6                   |team28|\n",
      "|6        |6                   |team30|\n",
      "|6        |7                   |team33|\n",
      "|3        |6                   |team34|\n",
      "|4        |5                   |team40|\n",
      "+---------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[team_size: int, avg_experience_years: int, team: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_csv = \"mc/team.csv\"\n",
    "team = spark.read\\\n",
    "    .option(\"compression\", \"none\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"sep\", ',')\\\n",
    "    .option(\"nullValue\", np.nan)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(path_to_csv)\\\n",
    "    .withColumn(\"team\", concat(lit(\"team\"), regexp_extract(col(\"team_id\"), r'^team[0]*(.*)$', 1)))\\\n",
    "    .drop(\"team_id\")\\\n",
    "    .orderBy(col(\"team\").asc())\n",
    "\n",
    "team.printSchema()\n",
    "team.show(5, truncate=False)\n",
    "team.createOrReplaceTempView(\"team\")\n",
    "team.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974f2e1",
   "metadata": {},
   "source": [
    "# Tickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eefac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickets 30000\n",
      "root\n",
      " |-- ticket_id: string (nullable = true)\n",
      " |-- alarm: integer (nullable = true)\n",
      " |-- started_ts: string (nullable = true)\n",
      " |-- ended_ts: string (nullable = true)\n",
      " |-- solved_by: string (nullable = true)\n",
      " |-- src_system: string (nullable = true)\n",
      " |-- site_visit: integer (nullable = true)\n",
      " |-- priority: integer (nullable = true)\n",
      "\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|ticket_id|alarm   |started_ts         |ended_ts           |solved_by|src_system|site_visit|priority|\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|T_0000001|50025222|2018-09-14 03:29:10|14-09-2018 04.06.13|team78   |OP2       |1         |3       |\n",
      "|T_0000002|50021238|2018-10-29 03:39:49|29/10/2018 04:25:25|team30   |OP1       |0         |2       |\n",
      "|T_0000003|50034089|2018-03-31 07:25:48|31/03/2018 07:58:45|team68   |OP1       |0         |3       |\n",
      "|T_0000004|50021918|2018-08-08 19:57:56|08/08/2018 20:42:40|team56   |OP1       |0         |2       |\n",
      "|T_0000005|50046096|2018-10-10 17:47:00|10/10/2018 18:31:05|team34   |OP1       |0         |3       |\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_csv = \"mc/tickets.dat\"\n",
    "date_format = \"yyyy-MM-dd\"\n",
    "\n",
    "all_tickets = spark.read\\\n",
    "    .option(\"compression\", \"none\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"sep\", '|')\\\n",
    "    .option(\"nullValue\", np.nan)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(path_to_csv)\\\n",
    "\n",
    "num_tickets_total = all_tickets.count()\n",
    "print(\"Total tickets {}\".format(num_tickets_total))\n",
    "all_tickets.printSchema()\n",
    "all_tickets.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae482a7c",
   "metadata": {},
   "source": [
    "## Tickets - rows whose column X has null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b18a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ticket_id: all rows are valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column alarm: all rows are valid.\n",
      "Column started_ts: all rows are valid.\n",
      "Column ended_ts: there are 2974 rows where column is null:\n",
      "+---------+--------+-------------------+--------+---------+----------+----------+--------+\n",
      "|ticket_id|alarm   |started_ts         |ended_ts|solved_by|src_system|site_visit|priority|\n",
      "+---------+--------+-------------------+--------+---------+----------+----------+--------+\n",
      "|T_0000019|50010378|2018-01-04 06:22:13|null    |team28   |OP2       |0         |3       |\n",
      "|T_0000020|50037567|2018-12-13 05:30:25|null    |team56   |OP1       |1         |3       |\n",
      "|T_0000036|50038539|2018-11-24 19:15:01|null    |team48   |OP2       |0         |1       |\n",
      "|T_0000038|50009171|2018-02-19 02:56:04|null    |team68   |OP2       |1         |3       |\n",
      "|T_0000049|50028391|2018-09-15 03:52:11|null    |team28   |OP2       |0         |1       |\n",
      "|T_0000062|50046516|2018-04-12 21:23:58|null    |team48   |OP2       |0         |2       |\n",
      "|T_0000063|50019490|2018-08-10 00:10:55|null    |team48   |OP1       |0         |2       |\n",
      "|T_0000094|50030982|2018-01-25 21:03:55|null    |team30   |OP1       |0         |2       |\n",
      "|T_0000102|50023350|2018-10-29 19:33:37|null    |team90   |OP1       |1         |3       |\n",
      "|T_0000121|50020890|2018-07-09 17:45:48|null    |team30   |OP1       |0         |2       |\n",
      "|T_0000125|50024402|2018-12-16 21:31:35|null    |team90   |OP1       |0         |2       |\n",
      "|T_0000127|50039257|2018-07-16 10:39:45|null    |team48   |OP1       |1         |3       |\n",
      "|T_0000138|50014703|2018-11-26 15:23:28|null    |team90   |OP1       |0         |1       |\n",
      "|T_0000144|50015195|2018-02-06 11:49:53|null    |team30   |OP1       |0         |1       |\n",
      "|T_0000149|50004722|2018-11-26 12:43:45|null    |team28   |OP2       |0         |2       |\n",
      "|T_0000161|50002105|2018-05-24 18:56:51|null    |team28   |OP2       |0         |2       |\n",
      "|T_0000162|50010410|2018-04-12 12:51:53|null    |team68   |OP1       |0         |2       |\n",
      "|T_0000166|50013428|2018-08-16 12:06:01|null    |team34   |OP1       |1         |3       |\n",
      "|T_0000169|50023750|2018-09-25 10:32:23|null    |team78   |OP2       |0         |3       |\n",
      "|T_0000179|50008994|2018-06-22 15:52:01|null    |team90   |OP1       |1         |3       |\n",
      "+---------+--------+-------------------+--------+---------+----------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Column solved_by: all rows are valid.\n",
      "Column src_system: all rows are valid.\n",
      "Column site_visit: all rows are valid.\n",
      "Column priority: all rows are valid.\n"
     ]
    }
   ],
   "source": [
    "num_tickets_with_null = {}\n",
    "for column in all_tickets.columns:\n",
    "    nulls = all_tickets.where(col(column).isNull())\n",
    "    if nulls.count() > 0:\n",
    "        num_nulls = all_tickets.where(col(\"ended_ts\").isNull()).count()\n",
    "        num_tickets_with_null[column] = num_nulls\n",
    "        print(\"Column {}: there are {} rows where column is null:\".format(\n",
    "            column,\n",
    "            num_nulls\n",
    "        ))\n",
    "        nulls.show(truncate=False)\n",
    "    else:\n",
    "        print(\"Column {}: all rows are valid.\".format(column))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13260b2",
   "metadata": {},
   "source": [
    "## Tickets with no null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee52207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tickets with no null 27026\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|ticket_id|alarm   |started_ts         |ended_ts           |solved_by|src_system|site_visit|priority|\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|T_0000001|50025222|2018-09-14 03:29:10|14-09-2018 04.06.13|team78   |OP2       |1         |3       |\n",
      "|T_0000002|50021238|2018-10-29 03:39:49|29/10/2018 04:25:25|team30   |OP1       |0         |2       |\n",
      "|T_0000003|50034089|2018-03-31 07:25:48|31/03/2018 07:58:45|team68   |OP1       |0         |3       |\n",
      "|T_0000004|50021918|2018-08-08 19:57:56|08/08/2018 20:42:40|team56   |OP1       |0         |2       |\n",
      "|T_0000005|50046096|2018-10-10 17:47:00|10/10/2018 18:31:05|team34   |OP1       |0         |3       |\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_csv = \"mc/tickets.dat\"\n",
    "date_format = \"yyyy-MM-dd\"\n",
    "\n",
    "tickets_cleaned = spark.read\\\n",
    "    .option(\"compression\", \"none\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"sep\", '|')\\\n",
    "    .option(\"nullValue\", np.nan)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(path_to_csv)\\\n",
    "    .where(col(\"ended_ts\").isNotNull())\n",
    "\n",
    "num_tickets_no_null = tickets_cleaned.count()\n",
    "print(\"Number of tickets with no null {}\".format(num_tickets_no_null))\n",
    "tickets_cleaned.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100d2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_tickets_total == (num_tickets_no_null + sum(num_tickets_with_null.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbca9f",
   "metadata": {},
   "source": [
    "## Clean the ended_ts date\n",
    "\n",
    "The format of the timestamp in ended_ts is not consistent. Some have ```14-09-2018``` and others have ```29/10/2018```. Make the timeformat consistent with ```dd-MM-yyyy HH:mm:ss```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0be9635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticket_id: string (nullable = true)\n",
      " |-- alarm: integer (nullable = true)\n",
      " |-- started_ts: string (nullable = true)\n",
      " |-- ended_ts: timestamp (nullable = true)\n",
      " |-- solved_by: string (nullable = true)\n",
      " |-- src_system: string (nullable = true)\n",
      " |-- site_visit: integer (nullable = true)\n",
      " |-- priority: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|ticket_id|alarm   |started_ts         |ended_ts           |solved_by|src_system|site_visit|priority|\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "|T_0000001|50025222|2018-09-14 03:29:10|2018-09-14 04:06:13|team78   |OP2       |1         |3       |\n",
      "|T_0000002|50021238|2018-10-29 03:39:49|2018-10-29 04:25:25|team30   |OP1       |0         |2       |\n",
      "|T_0000003|50034089|2018-03-31 07:25:48|2018-03-31 07:58:45|team68   |OP1       |0         |3       |\n",
      "|T_0000004|50021918|2018-08-08 19:57:56|2018-08-08 20:42:40|team56   |OP1       |0         |2       |\n",
      "|T_0000005|50046096|2018-10-10 17:47:00|2018-10-10 18:31:05|team34   |OP1       |0         |3       |\n",
      "+---------+--------+-------------------+-------------------+---------+----------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tickets = tickets_cleaned\\\n",
    "    .withColumn(\"ended_ts\", regexp_replace(\"ended_ts\", \"/\", \"-\"))\\\n",
    "    .withColumn(\"ended_ts\", regexp_replace(\"ended_ts\", \"\\.\", \":\"))\\\n",
    "    .withColumn(\"ended_ts\", to_timestamp(col('ended_ts'), \"dd-MM-yyyy HH:mm:ss\"))\\\n",
    "\n",
    "tickets.printSchema()\n",
    "tickets.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ece145",
   "metadata": {},
   "source": [
    "## Extract year/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfc8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticket_id: string (nullable = true)\n",
      " |-- alarm: integer (nullable = true)\n",
      " |-- started_ts: string (nullable = true)\n",
      " |-- ended_ts: timestamp (nullable = true)\n",
      " |-- team: string (nullable = true)\n",
      " |-- src_system: string (nullable = true)\n",
      " |-- site_visit: integer (nullable = true)\n",
      " |-- priority: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------------+-------------------+------+----------+----------+--------+----+-----+\n",
      "|ticket_id|alarm   |started_ts         |ended_ts           |team  |src_system|site_visit|priority|year|month|\n",
      "+---------+--------+-------------------+-------------------+------+----------+----------+--------+----+-----+\n",
      "|T_0000001|50025222|2018-09-14 03:29:10|2018-09-14 04:06:13|team78|OP2       |1         |3       |2018|9    |\n",
      "|T_0000002|50021238|2018-10-29 03:39:49|2018-10-29 04:25:25|team30|OP1       |0         |2       |2018|10   |\n",
      "|T_0000003|50034089|2018-03-31 07:25:48|2018-03-31 07:58:45|team68|OP1       |0         |3       |2018|3    |\n",
      "|T_0000004|50021918|2018-08-08 19:57:56|2018-08-08 20:42:40|team56|OP1       |0         |2       |2018|8    |\n",
      "|T_0000005|50046096|2018-10-10 17:47:00|2018-10-10 18:31:05|team34|OP1       |0         |3       |2018|10   |\n",
      "+---------+--------+-------------------+-------------------+------+----------+----------+--------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tickets = tickets_cleaned\\\n",
    "    .withColumnRenamed(\"solved_by\", \"team\")\\\n",
    "    .withColumn(\"ended_ts\", regexp_replace(\"ended_ts\", \"/\", \"-\"))\\\n",
    "    .withColumn(\"ended_ts\", regexp_replace(\"ended_ts\", \"\\.\", \":\"))\\\n",
    "    .withColumn(\"ended_ts\", to_timestamp(col('ended_ts'), \"dd-MM-yyyy HH:mm:ss\"))\\\n",
    "    .withColumn(\"year\", year(col(\"ended_ts\")))\\\n",
    "    .withColumn(\"month\", month(col(\"ended_ts\")))\n",
    "\n",
    "tickets.printSchema()\n",
    "tickets.show(5, truncate=False)\n",
    "tickets.cache()\n",
    "tickets.createOrReplaceTempView(\"tickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1e3ed",
   "metadata": {},
   "source": [
    "# Alarms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dcba6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alarm_id: long (nullable = true)\n",
      " |-- alarm_src: struct (nullable = true)\n",
      " |    |-- MeContext: string (nullable = true)\n",
      " |    |-- Network: string (nullable = true)\n",
      " |    |-- SubNetwork: string (nullable = true)\n",
      " |-- event_end_ts: long (nullable = true)\n",
      " |-- event_start_ts: long (nullable = true)\n",
      " |-- issue_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------------------+-------------+--------------+----------------+\n",
      "|alarm_id|alarm_src                          |event_end_ts |event_start_ts|issue_type      |\n",
      "+--------+-----------------------------------+-------------+--------------+----------------+\n",
      "|50000001|{LON75UTM3265, UK_TEL_LON, LON75}  |1525685613000|1525683343000 |                |\n",
      "|50000002|{LON47UTM3159, UK_TEL_LON, LON47}  |1533618469000|1533610843000 |                |\n",
      "|50000003|{LON75GSM2884, UK_TEL_LON, LON75}  |1541645693000|1541637429000 |3g_failure      |\n",
      "|50000004|{LON187GSM2391, UK_TEL_LON, LON187}|1525604682000|1525599471000 |power_failure   |\n",
      "|50000005|{LON111LTE4170, UK_TEL_LON, LON111}|1541342376000|1541335278000 |power_failure   |\n",
      "|50000006|{LON75GSM2884, UK_TEL_LON, LON75}  |1533844097000|1533841992000 |                |\n",
      "|50000007|{LON33GSM2601, UK_TEL_LON, LON33}  |1530752968000|1530743892000 |speed_issues    |\n",
      "|50000008|{LON187LTE4202, UK_TEL_LON, LON187}|1532234526000|1532227123000 |power_failure   |\n",
      "|50000009|{LON10UTM3870, UK_TEL_LON, LON10}  |1516540419000|1516535411000 |high_temperature|\n",
      "|50000010|{LON37GSM2364, UK_TEL_LON, LON37}  |1540334084000|1540331010000 |2g_failure      |\n",
      "|50000011|{LON187GSM2391, UK_TEL_LON, LON187}|1518941321000|1518933506000 |2g_failure      |\n",
      "|50000012|{LON106LTE4901, UK_TEL_LON, LON106}|1538956219000|1538952922000 |hw_issue        |\n",
      "|50000013|{LON181UTM3309, UK_TEL_LON, LON181}|1535634717000|1535631870000 |hw_issue        |\n",
      "|50000014|{LON75UTM3265, UK_TEL_LON, LON75}  |1538241276000|1538235040000 |up_link_failed  |\n",
      "|50000015|{LON106GSM2550, UK_TEL_LON, LON106}|1536323561000|1536314983000 |3g_failure      |\n",
      "|50000016|{LON71LTE4248, UK_TEL_LON, LON71}  |1543762963000|1543753807000 |                |\n",
      "|50000017|{LON10UTM3556, UK_TEL_LON, LON10}  |1529428786000|1529425635000 |up_link_failed  |\n",
      "|50000018|{LON126UTM3553, UK_TEL_LON, LON126}|1540556629000|1540550202000 |battery_broken  |\n",
      "|50000019|{LON114UTM3701, UK_TEL_LON, LON114}|1532129030000|1532124021000 |hw_issue        |\n",
      "|50000020|{LON111UTM3087, UK_TEL_LON, LON111}|1541927093000|1541918825000 |2g_failure      |\n",
      "+--------+-----------------------------------+-------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preview = spark.read\\\n",
    "    .option(\"compression\", \"none\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .json(\"mc/alarms.json\")\n",
    "\n",
    "preview.printSchema()\n",
    "preview.show(truncate=False)\n",
    "del preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4c2bf",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1\n",
    "\n",
    "Produce a table showing the nubmer of tickets each team solved.\n",
    "\n",
    "* team: Team name\n",
    "* tickets_priority_1_count: Number of priority 1 tickets the team solved\n",
    "* tickets_priority_2_count\n",
    "* tickets_priority_3_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24c29f",
   "metadata": {},
   "source": [
    "## Sample format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc1f724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>tickets_priority_1_count</th>\n",
       "      <th>tickets_priorityb_2_count</th>\n",
       "      <th>tickets_priority_3_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team90</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team90</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>team30</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team33</td>\n",
       "      <td>97</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team28</td>\n",
       "      <td>93</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  tickets_priority_1_count  tickets_priorityb_2_count  \\\n",
       "0  team90                        40                         25   \n",
       "1  team90                        18                         51   \n",
       "2  team30                        82                          5   \n",
       "3  team33                        97                         40   \n",
       "4  team28                        93                         52   \n",
       "\n",
       "   tickets_priority_3_count  \n",
       "0                        34  \n",
       "1                        24  \n",
       "2                        45  \n",
       "3                         0  \n",
       "4                        36  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example output schema (using generated mock data)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "teams = ['team78', 'team30', 'team68', 'team56', 'team34', 'team48',\n",
    "       'team28', 'team33', 'team90']\n",
    "example_output_q3 = pd.DataFrame(\n",
    "    {'team': np.random.choice(teams, 24),\n",
    "     'tickets_priority_1_count': np.random.randint(0,100,24),\n",
    "     'tickets_priorityb_2_count': np.random.randint(0,100,24),\n",
    "     'tickets_priority_3_count': np.random.randint(0,100,24)}\n",
    ")\n",
    "example_output_q3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222982cc",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "First, create the long format (stacked) where (attribute,value) = (priority, num_tickets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b74b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+\n",
      "|team  |priority|num_tickets|\n",
      "+------+--------+-----------+\n",
      "|team28|1       |386        |\n",
      "|team28|3       |1620       |\n",
      "|team28|2       |964        |\n",
      "|team30|3       |1674       |\n",
      "|team30|1       |318        |\n",
      "|team30|2       |1021       |\n",
      "|team33|1       |326        |\n",
      "|team33|2       |1033       |\n",
      "|team33|3       |1605       |\n",
      "|team34|2       |963        |\n",
      "|team34|1       |355        |\n",
      "|team34|3       |1578       |\n",
      "|team48|1       |365        |\n",
      "|team48|3       |1696       |\n",
      "|team48|2       |981        |\n",
      "|team56|1       |323        |\n",
      "|team56|2       |1019       |\n",
      "|team56|3       |1696       |\n",
      "|team68|2       |1067       |\n",
      "|team68|1       |287        |\n",
      "+------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH team_priority_tickets AS (\n",
    "    SELECT\n",
    "        team,\n",
    "        priority as priority,\n",
    "        count(*) AS num_tickets\n",
    "    FROM\n",
    "        tickets\n",
    "    GROUP BY\n",
    "        team,\n",
    "        priority\n",
    "    ORDER BY\n",
    "        team\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    team_priority_tickets\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d3e7f",
   "metadata": {},
   "source": [
    "Then PIVOT the (attribute, value) to Wide Format (Unstacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01528102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:============================>                            (6 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------+------------------------+------------------------+\n",
      "|team  |tickets_priority_1_count|tickets_priority_2_count|tickets_priority_3_count|\n",
      "+------+------------------------+------------------------+------------------------+\n",
      "|team28|386                     |964                     |1620                    |\n",
      "|team30|318                     |1021                    |1674                    |\n",
      "|team33|326                     |1033                    |1605                    |\n",
      "|team34|355                     |963                     |1578                    |\n",
      "|team48|365                     |981                     |1696                    |\n",
      "|team56|323                     |1019                    |1696                    |\n",
      "|team68|287                     |1067                    |1677                    |\n",
      "|team78|353                     |1023                    |1711                    |\n",
      "|team90|325                     |999                     |1661                    |\n",
      "+------+------------------------+------------------------+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH team_priority_tickets AS (\n",
    "    SELECT\n",
    "        team,\n",
    "        priority as priority,\n",
    "        count(*) AS num_tickets\n",
    "    FROM\n",
    "        tickets\n",
    "    GROUP BY\n",
    "        team,\n",
    "        priority\n",
    "    ORDER BY\n",
    "        team\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    team_priority_tickets\n",
    "PIVOT (\n",
    "    SUM(num_tickets)\n",
    "    FOR priority IN (\n",
    "        1 AS tickets_priority_1_count,\n",
    "        2 AS tickets_priority_2_count,\n",
    "        3 AS tickets_priority_3_count\n",
    "    )\n",
    ")\n",
    "ORDER BY\n",
    "    team\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf467d7c",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 2\n",
    "\n",
    "Create a dataframe with the columns:\n",
    "\n",
    "- year\n",
    "- month\n",
    "- team\n",
    "- team size\n",
    "- tickets solved in the current month\n",
    "- tickets solved in the previous year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be0390",
   "metadata": {},
   "source": [
    "## Sample format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29936256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>team</th>\n",
       "      <th>team_size</th>\n",
       "      <th>tickets_solved_in_the_current_month</th>\n",
       "      <th>tickets_solved_in_the_previous_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>team34</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>team56</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>team30</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>team30</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>team33</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month    team  team_size  tickets_solved_in_the_current_month  \\\n",
       "0  2018      1  team34          2                                   71   \n",
       "1  2018      2  team56          3                                   57   \n",
       "2  2018      3  team30          2                                   62   \n",
       "3  2018      4  team30          5                                    6   \n",
       "4  2018      5  team33          4                                   14   \n",
       "\n",
       "   tickets_solved_in_the_previous_year  \n",
       "0                                   38  \n",
       "1                                   60  \n",
       "2                                   30  \n",
       "3                                   40  \n",
       "4                                   56  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example output schema (using generated mock data)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "teams = ['team78', 'team30', 'team68', 'team56', 'team34', 'team48',\n",
    "       'team28', 'team33', 'team90']\n",
    "example_output_q4 = pd.DataFrame(\n",
    "    {'year': [2018]*12 + [2019]*12,\n",
    "     'month': list(range(1,13))*2,\n",
    "     'team': np.random.choice(teams, 24),\n",
    "     'team_size': np.random.randint(1,6,24),\n",
    "     'tickets_solved_in_the_current_month': np.random.randint(0,100,24),\n",
    "     'tickets_solved_in_the_previous_year': np.random.randint(0,100,24)}\n",
    ")\n",
    "example_output_q4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daf97f",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532682d2",
   "metadata": {},
   "source": [
    "First, extract year and month as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b98845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=================================>                       (7 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+-----------------------------------+-----------------------------------+\n",
      "|year|month|team  |team_size|tickets_solved_in_the_current_month|tickets_solved_in_the_previous_year|\n",
      "+----+-----+------+---------+-----------------------------------+-----------------------------------+\n",
      "|2019|1    |team34|3        |1                                  |2895                               |\n",
      "|2019|1    |team48|6        |1                                  |3041                               |\n",
      "|2019|1    |team56|5        |2                                  |3035                               |\n",
      "|2019|1    |team78|5        |1                                  |3086                               |\n",
      "|2018|1    |team28|6        |253                                |null                               |\n",
      "|2018|1    |team30|6        |266                                |null                               |\n",
      "|2018|1    |team33|6        |262                                |null                               |\n",
      "|2018|1    |team34|3        |252                                |null                               |\n",
      "|2018|1    |team48|6        |270                                |null                               |\n",
      "|2018|1    |team56|5        |278                                |null                               |\n",
      "|2018|1    |team68|5        |274                                |null                               |\n",
      "|2018|1    |team78|5        |287                                |null                               |\n",
      "|2018|1    |team90|5        |231                                |null                               |\n",
      "|2018|2    |team28|6        |208                                |null                               |\n",
      "|2018|2    |team30|6        |249                                |null                               |\n",
      "|2018|2    |team33|6        |217                                |null                               |\n",
      "|2018|2    |team34|3        |185                                |null                               |\n",
      "|2018|2    |team48|6        |220                                |null                               |\n",
      "|2018|2    |team56|5        |229                                |null                               |\n",
      "|2018|2    |team68|5        |219                                |null                               |\n",
      "+----+-----+------+---------+-----------------------------------+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:==============================================>         (10 + 2) / 12]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH year_month_team AS (\n",
    "    SELECT\n",
    "        year,\n",
    "        month,\n",
    "        team,\n",
    "        count(*) AS tickets_solved_in_the_current_month\n",
    "    FROM\n",
    "        tickets\n",
    "    GROUP BY\n",
    "        year,\n",
    "        month,\n",
    "        team        \n",
    "    ORDER BY\n",
    "        year,\n",
    "        month,\n",
    "        team        \n",
    "),\n",
    "year_team AS (\n",
    "    SELECT\n",
    "        year,\n",
    "        team,\n",
    "        count(*) AS tickets_solved_in_the_year\n",
    "    FROM\n",
    "        tickets\n",
    "    GROUP BY\n",
    "        year,\n",
    "        team        \n",
    "    ORDER BY\n",
    "        year,\n",
    "        team       \n",
    ")\n",
    "SELECT DISTINCT\n",
    "    o.year,\n",
    "    o.month,\n",
    "    o.team,\n",
    "    t.team_size,\n",
    "    o.tickets_solved_in_the_current_month,\n",
    "    i.tickets_solved_in_the_year AS tickets_solved_in_the_previous_year\n",
    "FROM\n",
    "    year_month_team o\n",
    "    INNER JOIN team t\n",
    "        ON o.team = t.team\n",
    "    LEFT OUTER JOIN year_team i \n",
    "        ON i.team = o.team AND i.year = (o.year - 1)\n",
    "ORDER BY\n",
    "    year desc,\n",
    "    month,\n",
    "    team\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed483b7",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Create a function that accepts alarms records (part) and returns the alarm network type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5542862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alarm_id: long (nullable = true)\n",
      " |-- part: string (nullable = true)\n",
      " |-- network: string (nullable = true)\n",
      " |-- subnet: string (nullable = true)\n",
      " |-- event_start_ts: long (nullable = true)\n",
      " |-- event_end_ts: long (nullable = true)\n",
      " |-- start_date: date (nullable = true)\n",
      " |-- end_date: date (nullable = true)\n",
      " |-- issue_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 49:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+\n",
      "|alarm_id|part         |network   |subnet|event_start_ts|event_end_ts |start_date|end_date  |issue_type      |\n",
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+\n",
      "|50000001|LON75UTM3265 |UK_TEL_LON|LON75 |1525683343000 |1525685613000|2018-05-07|2018-05-07|                |\n",
      "|50000002|LON47UTM3159 |UK_TEL_LON|LON47 |1533610843000 |1533618469000|2018-08-07|2018-08-07|                |\n",
      "|50000003|LON75GSM2884 |UK_TEL_LON|LON75 |1541637429000 |1541645693000|2018-11-08|2018-11-08|3g_failure      |\n",
      "|50000004|LON187GSM2391|UK_TEL_LON|LON187|1525599471000 |1525604682000|2018-05-06|2018-05-06|power_failure   |\n",
      "|50000005|LON111LTE4170|UK_TEL_LON|LON111|1541335278000 |1541342376000|2018-11-04|2018-11-05|power_failure   |\n",
      "|50000006|LON75GSM2884 |UK_TEL_LON|LON75 |1533841992000 |1533844097000|2018-08-10|2018-08-10|                |\n",
      "|50000007|LON33GSM2601 |UK_TEL_LON|LON33 |1530743892000 |1530752968000|2018-07-05|2018-07-05|speed_issues    |\n",
      "|50000008|LON187LTE4202|UK_TEL_LON|LON187|1532227123000 |1532234526000|2018-07-22|2018-07-22|power_failure   |\n",
      "|50000009|LON10UTM3870 |UK_TEL_LON|LON10 |1516535411000 |1516540419000|2018-01-21|2018-01-22|high_temperature|\n",
      "|50000010|LON37GSM2364 |UK_TEL_LON|LON37 |1540331010000 |1540334084000|2018-10-24|2018-10-24|2g_failure      |\n",
      "|50000011|LON187GSM2391|UK_TEL_LON|LON187|1518933506000 |1518941321000|2018-02-18|2018-02-18|2g_failure      |\n",
      "|50000012|LON106LTE4901|UK_TEL_LON|LON106|1538952922000 |1538956219000|2018-10-08|2018-10-08|hw_issue        |\n",
      "|50000013|LON181UTM3309|UK_TEL_LON|LON181|1535631870000 |1535634717000|2018-08-30|2018-08-30|hw_issue        |\n",
      "|50000014|LON75UTM3265 |UK_TEL_LON|LON75 |1538235040000 |1538241276000|2018-09-30|2018-09-30|up_link_failed  |\n",
      "|50000015|LON106GSM2550|UK_TEL_LON|LON106|1536314983000 |1536323561000|2018-09-07|2018-09-07|3g_failure      |\n",
      "|50000016|LON71LTE4248 |UK_TEL_LON|LON71 |1543753807000 |1543762963000|2018-12-02|2018-12-03|                |\n",
      "|50000017|LON10UTM3556 |UK_TEL_LON|LON10 |1529425635000 |1529428786000|2018-06-20|2018-06-20|up_link_failed  |\n",
      "|50000018|LON126UTM3553|UK_TEL_LON|LON126|1540550202000 |1540556629000|2018-10-26|2018-10-26|battery_broken  |\n",
      "|50000019|LON114UTM3701|UK_TEL_LON|LON114|1532124021000 |1532129030000|2018-07-21|2018-07-21|hw_issue        |\n",
      "|50000020|LON111UTM3087|UK_TEL_LON|LON111|1541918825000 |1541927093000|2018-11-11|2018-11-11|2g_failure      |\n",
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alarms = spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .json(\"mc/alarms.json\")\\\n",
    "    .select(\n",
    "        \"alarm_id\",\n",
    "        col(\"alarm_src.MeContext\").alias(\"part\"),    \n",
    "        col(\"alarm_src.Network\").alias(\"network\"),    \n",
    "        col(\"alarm_src.SubNetwork\").alias(\"subnet\"),    \n",
    "        col(\"event_start_ts\"),    \n",
    "        col(\"event_end_ts\"),    \n",
    "        to_date(\n",
    "            from_unixtime(col(\"event_start_ts\") / 1000),\n",
    "            \"yyyy-MM-dd\"\n",
    "        ).alias(\"start_date\"),\n",
    "        to_date(\n",
    "            from_unixtime(col(\"event_end_ts\") / 1000),\n",
    "            \"yyyy-MM-dd\"\n",
    "        ).alias(\"end_date\"),\n",
    "        col(\"issue_type\"),    \n",
    "    )\n",
    "alarms.printSchema()\n",
    "alarms.show(truncate=False)\n",
    "alarms.cache()\n",
    "alarms.createOrReplaceTempView(\"alarms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54aed79",
   "metadata": {},
   "source": [
    "### UDF to extract the network type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c65552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def get_networ_type(part: str) -> str:\n",
    "    \"\"\"Get the Network Type for the tower\n",
    "    Args:\n",
    "        part: Part of the tower having the problem.\n",
    "    Returns:\n",
    "        Network Type which is either LTE or UTM, or GSM.\n",
    "    \"\"\"\n",
    "    if (part is not None) and (part != np.nan) and isinstance(part, str):\n",
    "        part = part.lower()\n",
    "        for kind in [\"gsm\", \"lte\", \"utm\"]:\n",
    "            if kind in part:\n",
    "                return kind.upper()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "076cef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|alarm_id|network_type|\n",
      "+--------+------------+\n",
      "|50000001|         UTM|\n",
      "|50000002|         UTM|\n",
      "|50000003|         GSM|\n",
      "|50000004|         GSM|\n",
      "|50000005|         LTE|\n",
      "|50000006|         GSM|\n",
      "|50000007|         GSM|\n",
      "|50000008|         LTE|\n",
      "|50000009|         UTM|\n",
      "|50000010|         GSM|\n",
      "|50000011|         GSM|\n",
      "|50000012|         LTE|\n",
      "|50000013|         UTM|\n",
      "|50000014|         UTM|\n",
      "|50000015|         GSM|\n",
      "|50000016|         LTE|\n",
      "|50000017|         UTM|\n",
      "|50000018|         UTM|\n",
      "|50000019|         UTM|\n",
      "|50000020|         UTM|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "alarms.select(\n",
    "    \"alarm_id\",\n",
    "    get_networ_type(\"part\").alias(\"network_type\")\n",
    ").where(col(\"network_type\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1b053ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+------------+\n",
      "|alarm_id|         part|   network|subnet|event_start_ts| event_end_ts|start_date|  end_date|      issue_type|network_type|\n",
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+------------+\n",
      "|50000001| LON75UTM3265|UK_TEL_LON| LON75| 1525683343000|1525685613000|2018-05-07|2018-05-07|                |         UTM|\n",
      "|50000002| LON47UTM3159|UK_TEL_LON| LON47| 1533610843000|1533618469000|2018-08-07|2018-08-07|                |         UTM|\n",
      "|50000003| LON75GSM2884|UK_TEL_LON| LON75| 1541637429000|1541645693000|2018-11-08|2018-11-08|      3g_failure|         GSM|\n",
      "|50000004|LON187GSM2391|UK_TEL_LON|LON187| 1525599471000|1525604682000|2018-05-06|2018-05-06|   power_failure|         GSM|\n",
      "|50000005|LON111LTE4170|UK_TEL_LON|LON111| 1541335278000|1541342376000|2018-11-04|2018-11-05|   power_failure|         LTE|\n",
      "|50000006| LON75GSM2884|UK_TEL_LON| LON75| 1533841992000|1533844097000|2018-08-10|2018-08-10|                |         GSM|\n",
      "|50000007| LON33GSM2601|UK_TEL_LON| LON33| 1530743892000|1530752968000|2018-07-05|2018-07-05|    speed_issues|         GSM|\n",
      "|50000008|LON187LTE4202|UK_TEL_LON|LON187| 1532227123000|1532234526000|2018-07-22|2018-07-22|   power_failure|         LTE|\n",
      "|50000009| LON10UTM3870|UK_TEL_LON| LON10| 1516535411000|1516540419000|2018-01-21|2018-01-22|high_temperature|         UTM|\n",
      "|50000010| LON37GSM2364|UK_TEL_LON| LON37| 1540331010000|1540334084000|2018-10-24|2018-10-24|      2g_failure|         GSM|\n",
      "|50000011|LON187GSM2391|UK_TEL_LON|LON187| 1518933506000|1518941321000|2018-02-18|2018-02-18|      2g_failure|         GSM|\n",
      "|50000012|LON106LTE4901|UK_TEL_LON|LON106| 1538952922000|1538956219000|2018-10-08|2018-10-08|        hw_issue|         LTE|\n",
      "|50000013|LON181UTM3309|UK_TEL_LON|LON181| 1535631870000|1535634717000|2018-08-30|2018-08-30|        hw_issue|         UTM|\n",
      "|50000014| LON75UTM3265|UK_TEL_LON| LON75| 1538235040000|1538241276000|2018-09-30|2018-09-30|  up_link_failed|         UTM|\n",
      "|50000015|LON106GSM2550|UK_TEL_LON|LON106| 1536314983000|1536323561000|2018-09-07|2018-09-07|      3g_failure|         GSM|\n",
      "|50000016| LON71LTE4248|UK_TEL_LON| LON71| 1543753807000|1543762963000|2018-12-02|2018-12-03|                |         LTE|\n",
      "|50000017| LON10UTM3556|UK_TEL_LON| LON10| 1529425635000|1529428786000|2018-06-20|2018-06-20|  up_link_failed|         UTM|\n",
      "|50000018|LON126UTM3553|UK_TEL_LON|LON126| 1540550202000|1540556629000|2018-10-26|2018-10-26|  battery_broken|         UTM|\n",
      "|50000019|LON114UTM3701|UK_TEL_LON|LON114| 1532124021000|1532129030000|2018-07-21|2018-07-21|        hw_issue|         UTM|\n",
      "|50000020|LON111UTM3087|UK_TEL_LON|LON111| 1541918825000|1541927093000|2018-11-11|2018-11-11|      2g_failure|         UTM|\n",
      "+--------+-------------+----------+------+--------------+-------------+----------+----------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alarms.withColumn(\"network_type\", get_networ_type(\"part\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1928af9",
   "metadata": {},
   "source": [
    "---\n",
    "# Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a09e1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe597fb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71a6106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del spark\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
