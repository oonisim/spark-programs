{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a609ffd2",
   "metadata": {},
   "source": [
    "# PySpark SparkSQL on Student schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37098727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fc02f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e765d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc37261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    avg,\n",
    "    stddev,\n",
    "    isnan,\n",
    "    to_date,\n",
    "    to_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc892c",
   "metadata": {},
   "source": [
    "#  Environemnt Variables\n",
    "\n",
    "## Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = \"/opt/hadoop/hadoop-3.2.2/etc/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21805809",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export HADOOP_CONF_DIR=\"/opt/hadoop/hadoop-3.2.2/etc/hadoop\"\n",
    "ls $HADOOP_CONF_DIR | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ea383",
   "metadata": {},
   "source": [
    "## PYTHONPATH\n",
    "\n",
    "Refer to the **pyspark** modules to load from the ```$SPARK_HOME/python/lib``` in the Spark installation.\n",
    "\n",
    "* [PySpark Getting Started](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
    "\n",
    "> Ensure the SPARK_HOME environment variable points to the directory where the tar file has been extracted. Update PYTHONPATH environment variable such that it can find the PySpark and Py4J under SPARK_HOME/python/lib. One example of doing this is shown below:\n",
    "\n",
    "```\n",
    "export PYTHONPATH=$(ZIPS=(\"$SPARK_HOME\"/python/lib/*.zip); IFS=:; echo \"${ZIPS[*]}\"):$PYTHONPATH\n",
    "```\n",
    "\n",
    "Alternatively install **pyspark** with pip or conda locally which installs the Spark runtime libararies (for standalone).\n",
    "\n",
    "* [Can PySpark work without Spark?](https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark)\n",
    "\n",
    "> As of v2.2, executing pip install pyspark will install Spark. If you're going to use Pyspark it's clearly the simplest way to get started. On my system Spark is installed inside my virtual environment (miniconda) at lib/python3.6/site-packages/pyspark/jars  \n",
    "> PySpark has a Spark installation installed. If installed through pip3, you can find it with pip3 show pyspark. Ex. for me it is at ~/.local/lib/python3.8/site-packages/pyspark. This is a standalone configuration so it can't be used for managing clusters like a full Spark installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbbd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTHONPATH'] = \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip:/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "sys.path.extend([\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip\",\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b9883",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "* [The UC Irvine Machine Learning Repository  - Record Linkage Comparison Patterns Data Set](https://archive.ics.uci.edu/ml/datasets/Record+Linkage+Comparison+Patterns)\n",
    "\n",
    "The data are pairs of patient records to identify the two records refer to the same patient or not (na-yose in Japanse).It is from the record linkage study performed at a hospital in 2010 analyzing pairs of patient records that were matched according to several different criteria, such as the patientâ€™s name (first and last), address, and birthday. \n",
    "\n",
    "Each matching field was assigned a numerical score from 0.0 to 1.0 based on how similar the strings were, and the data was then hand-labeled to identify which pairs represented the same person and which did not. \n",
    "\n",
    "\n",
    "| feature | description  |\n",
    "|:---------|:--------------|\n",
    "| is_match| if the pair is a match or not (1: match)          |\n",
    "| cmp_sex | if the gender of the pair is a match (1:match)             |\n",
    "|         |              |\n",
    "|         |              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a5c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  student.zip\n",
      "  inflating: COURSE_DATA_TABLE.csv   \n",
      "  inflating: COURSE_REVENUE_DATA_TABLE.csv  \n",
      "  inflating: EMPLOYEE_DATA_TABLE.csv  \n",
      "  inflating: ENROLLMENT_DATA_TABLE.csv  \n",
      "  inflating: GRADE_DATA_TABLE.csv    \n",
      "  inflating: GRADE_TYPE_DATA_TABLE.csv  \n",
      "  inflating: INSTRUCTOR_DATA_TABLE.csv  \n",
      "  inflating: SECTION_DATA_TABLE.csv  \n",
      "  inflating: SECTION_HISTORY_DATA_TABLE.csv  \n",
      "  inflating: STUDENT_DATA_TABLE.csv  \n",
      "  inflating: ZIPCODE_DATA_TABLE.csv  \n",
      "COURSE_DATA_TABLE.csv\n",
      "COURSE_REVENUE_DATA_TABLE.csv\n",
      "EMPLOYEE_DATA_TABLE.csv\n",
      "ENROLLMENT_DATA_TABLE.csv\n",
      "GRADE_DATA_TABLE.csv\n",
      "GRADE_TYPE_DATA_TABLE.csv\n",
      "INSTRUCTOR_DATA_TABLE.csv\n",
      "SECTION_DATA_TABLE.csv\n",
      "SECTION_HISTORY_DATA_TABLE.csv\n",
      "STUDENT_DATA_TABLE.csv\n",
      "student.zip\n",
      "ZIPCODE_DATA_TABLE.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ./data/student\n",
    "unzip -o student.zip\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58ed336",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/student/\n",
    "hdfs dfs -mkdir -p student\n",
    "hdfs dfs -put -f *.csv student\n",
    "\n",
    "rm -rf *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84cdb11",
   "metadata": {},
   "source": [
    "---\n",
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d4da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4882cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 14:34:40,651 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-02-19 14:34:45,032 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.debug.maxToStringFields', 100) \\\n",
    "    .config('spark.executor.memory', '2g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc80e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 4\n",
    "NUM_PARTITIONS = 3\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201eac20",
   "metadata": {},
   "source": [
    "# Stduent schema CSV \n",
    "\n",
    "* [SparkSQL CSV Files](https://spark.apache.org/docs/latest/sql-data-sources-csv.html)\n",
    "\n",
    "> Spark SQL provides spark.read().csv(\"file_name\") to read a file or directory of files in CSV format into Spark DataFrame, and dataframe.write().csv(\"path\") to write to a CSV file. Function option() can be used to customize the behavior of reading or writing.\n",
    "\n",
    "[SparkSession.read()](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/SparkSession.html#read--) returns [DataFrameReader](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html) instance which has [option](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-boolean-) method by which we can specify CSV options.\n",
    "\n",
    "The options are listed in [Data Source Option](https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "19786163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- COST: integer (nullable = true)\n",
      " |-- PREREQUISITE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|COURSE_NO|         DESCRIPTION|COST|PREREQUISITE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|       10| Technology Concepts|1195|        null|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "|       20|Intro to Informat...|1195|        null|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "|       25|Intro to Programming|1195|         140|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/COURSE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "course.printSchema()\n",
    "course.createOrReplaceTempView(\"course\")\n",
    "course.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8bed4196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- SECTION_NO: integer (nullable = true)\n",
      " |-- START_DATE_TIME: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- CAPACITY: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|SECTION_ID|COURSE_NO|SECTION_NO|START_DATE_TIME|LOCATION|INSTRUCTOR_ID|CAPACITY|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|        79|      350|         3|      14-APR-07|    L509|          107|      25|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "|        80|       10|         2|      24-APR-07|    L214|          102|      15|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "|        81|       20|         2|      24-JUL-07|    L210|          103|      15|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/SECTION_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "section.printSchema()\n",
    "section.createOrReplaceTempView(\"section\")\n",
    "section.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8eecc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|INSTRUCTOR_ID|SALUTATION|FIRST_NAME|LAST_NAME|STREET_ADDRESS|  ZIP|     PHONE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|          101|        Mr|   Fernand|    Hanks| 100 East 87th|10015|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "|          102|        Mr|       Tom|   Wojick|518 West 120th|10025|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "|          103|        Ms|      Nina|  Schorin|210 West 101st|10025|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructor = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/INSTRUCTOR_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "instructor.printSchema()\n",
    "instructor.createOrReplaceTempView(\"instructor\")\n",
    "instructor.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2431110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- EMPLOYER: string (nullable = true)\n",
      " |-- REGISTRATION_DATE: date (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SALUTATION|FIRST_NAME|LAST_NAME|    STREET_ADDRESS|  ZIP|       PHONE|       EMPLOYER|REGISTRATION_DATE| CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|       167|       Mr.|       Jim|     Joas|   53-33 192nd St.|11365|718-555-5555|     Gaum, Inc.|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "|       168|       Ms.|     Sally|     Naso|      812 79th St.| 7047|201-555-5555|Motors National|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "|       169|       Mr.|    Frantz|   McLean|23-08 Newtown Ave.|11102|718-555-5555|Guenther Miller|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/STUDENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"REGISTRATION_DATE\", to_date(col('REGISTRATION_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"CREATED_DATE\",      to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\",     to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "student.cache()\n",
    "student.printSchema()\n",
    "student.createOrReplaceTempView(\"student\")\n",
    "student.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6cda60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- ENROLL_DATE: string (nullable = true)\n",
      " |-- FINAL_GRADE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|ENROLL_DATE|FINAL_GRADE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|       215|       146|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "|       215|       156|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "|       216|       154|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enrollment = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/ENROLLMENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "enrollment.cache()\n",
    "enrollment.printSchema()\n",
    "enrollment.createOrReplaceTempView(\"enrollment\")\n",
    "enrollment.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "492f7a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- GRADE_CODE_OCCURRENCE: integer (nullable = true)\n",
      " |-- NUMERIC_GRADE: integer (nullable = true)\n",
      " |-- COMMENTS: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|GRADE_TYPE_CODE|GRADE_CODE_OCCURRENCE|NUMERIC_GRADE|COMMENTS|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|       111|       133|             PA|                    6|           80|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "|       111|       133|             PA|                    7|           70|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "|       111|       133|             PA|                    8|           70|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/GRADE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "grade.printSchema()\n",
    "grade.createOrReplaceTempView(\"grade\")\n",
    "grade.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2c4f9",
   "metadata": {},
   "source": [
    "Need to make sure 31-DEC-98 is converted to 1998-12-31, not 2098-12-31.\n",
    "\n",
    "* [spark to_date function - how to convert 31-DEC-98 to 1998-12-31 not 2098-12-31](https://stackoverflow.com/questions/71182230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "db63aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|GRADE_TYPE_CODE|DESCRIPTION|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|             FI|      Final|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "|             HM|   Homework|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "|             MT|    Midterm|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade_type = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/GRADE_TYPE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "grade_type.printSchema()\n",
    "grade_type.createOrReplaceTempView(\"grade_type\")\n",
    "grade_type.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71037c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|  ZIP|            CITY|STATE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|11101|Long Island City|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11102|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11103|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipcode = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/ZIPCODE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "zipcode.printSchema()\n",
    "zipcode.createOrReplaceTempView(\"zipcode\")\n",
    "zipcode.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bce47923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      "\n",
      "+-----------+------+------+---------+\n",
      "|EMPLOYEE_ID|  NAME|SALARY|    TITLE|\n",
      "+-----------+------+------+---------+\n",
      "|          1|  John|  1000|  Analyst|\n",
      "|          2|  Mary|  2000|  Manager|\n",
      "|          3|Stella|  5000|President|\n",
      "+-----------+------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/EMPLOYEE_DATA_TABLE.csv\")\n",
    "\n",
    "employee.printSchema()\n",
    "employee.createOrReplaceTempView(\"employee\")\n",
    "employee.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b4e10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76f5d6",
   "metadata": {},
   "source": [
    "---\n",
    "# Sub Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9721a2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 152:====================================================> (97 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------------------------+\n",
      "|    cnt|avg_plz|std(CAST(cmp_sex AS DOUBLE))|\n",
      "+-------+-------+----------------------------+\n",
      "|  20931|0.95843|          0.1120157059121644|\n",
      "|5728201|0.00204|         0.20755988859217644|\n",
      "+-------+-------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(is_match) AS cnt,\n",
    "    ROUND(AVG(cmp_plz),5) AS avg_plz,\n",
    "    STD(cmp_sex)\n",
    "FROM linkage\n",
    "GROUP BY is_match\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b92ebc",
   "metadata": {},
   "source": [
    "## Join\n",
    "\n",
    "Calculate the diffence of mean values of the fields between matched records and unmatched records to identify the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eccf9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+----------+\n",
      "|matched_count|unmatch_count|    total|mean_delta|\n",
      "+-------------+-------------+---------+----------+\n",
      "|        20902|      5715387|5736289.0|     0.956|\n",
      "|          475|         1989|   2464.0|     0.806|\n",
      "|        20925|      5727412|5748337.0|     0.776|\n",
      "|        20925|      5727412|5748337.0|     0.775|\n",
      "|        20931|      5728201|5749132.0|     0.684|\n",
      "|        20925|      5727412|5748337.0|     0.511|\n",
      "|        20922|      5727203|5748125.0|     0.285|\n",
      "|         1333|       102365| 103698.0|     0.091|\n",
      "|        20931|      5728201|5749132.0|     0.032|\n",
      "+-------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    m.count AS matched_count,\n",
    "    u.count AS unmatch_count,\n",
    "    m.count + u.count as total,\n",
    "    ROUND(m.mean - u.mean, 3) as mean_delta\n",
    "FROM\n",
    "    matched AS m \n",
    "    INNER JOIN unmatched u ON m.field = u.field\n",
    "WHERE\n",
    "    m.field NOT IN ('id_1', 'id_2')\n",
    "ORDER BY \n",
    "    mean_delta desc\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1928af9",
   "metadata": {},
   "source": [
    "---\n",
    "# Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a09e1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe597fb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71a6106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2181"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del spark\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
