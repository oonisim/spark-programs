{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a609ffd2",
   "metadata": {},
   "source": [
    "# PySpark SparkSQL Analytics Functions\n",
    "\n",
    "* [SQL Summer Camp: Analytic Functions | Kaggle](https://www.youtube.com/watch?v=q1aL1XH69pQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37098727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fc02f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e765d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from datetime import (\n",
    "    datetime,\n",
    "    date\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc892c",
   "metadata": {},
   "source": [
    "#  Environemnt Variables\n",
    "\n",
    "## Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ee72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = \"/opt/hadoop/hadoop-3.2.2/etc/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21805809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capacity-scheduler.xml\n",
      "configuration.xsl\n",
      "container-executor.cfg\n",
      "core-site.xml\n",
      "core-site.xml.48132.2022-02-15@12:29:41~\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export HADOOP_CONF_DIR=\"/opt/hadoop/hadoop-3.2.2/etc/hadoop\"\n",
    "ls $HADOOP_CONF_DIR | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ea383",
   "metadata": {},
   "source": [
    "## PYTHONPATH\n",
    "\n",
    "Refer to the **pyspark** modules to load from the ```$SPARK_HOME/python/lib``` in the Spark installation.\n",
    "\n",
    "* [PySpark Getting Started](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
    "\n",
    "> Ensure the SPARK_HOME environment variable points to the directory where the tar file has been extracted. Update PYTHONPATH environment variable such that it can find the PySpark and Py4J under SPARK_HOME/python/lib. One example of doing this is shown below:\n",
    "\n",
    "```\n",
    "export PYTHONPATH=$(ZIPS=(\"$SPARK_HOME\"/python/lib/*.zip); IFS=:; echo \"${ZIPS[*]}\"):$PYTHONPATH\n",
    "```\n",
    "\n",
    "Alternatively install **pyspark** with pip or conda locally which installs the Spark runtime libararies (for standalone).\n",
    "\n",
    "* [Can PySpark work without Spark?](https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark)\n",
    "\n",
    "> As of v2.2, executing pip install pyspark will install Spark. If you're going to use Pyspark it's clearly the simplest way to get started. On my system Spark is installed inside my virtual environment (miniconda) at lib/python3.6/site-packages/pyspark/jars  \n",
    "> PySpark has a Spark installation installed. If installed through pip3, you can find it with pip3 show pyspark. Ex. for me it is at ~/.local/lib/python3.8/site-packages/pyspark. This is a standalone configuration so it can't be used for managing clusters like a full Spark installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbbd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTHONPATH'] = \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip:/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "sys.path.extend([\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip\",\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ec8dc",
   "metadata": {},
   "source": [
    "## PySpark packages\n",
    "\n",
    "Execute after the PYTHONPATH setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc37261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    avg,\n",
    "    stddev,\n",
    "    isnan,\n",
    "    to_date,\n",
    "    to_timestamp,\n",
    "    hour,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b9883",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Student schema from [Oracle SQL by Example](https://learning.oreilly.com/library/view/oracle-sql-by/9780137047345/ch06.html) located in ```./data/student```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a5c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  student.zip\n",
      "  inflating: COURSE_DATA_TABLE.csv   \n",
      "  inflating: COURSE_REVENUE_DATA_TABLE.csv  \n",
      "  inflating: EMPLOYEE_DATA_TABLE.csv  \n",
      "  inflating: ENROLLMENT_DATA_TABLE.csv  \n",
      "  inflating: GRADE_DATA_TABLE.csv    \n",
      "  inflating: GRADE_TYPE_DATA_TABLE.csv  \n",
      "  inflating: INSTRUCTOR_DATA_TABLE.csv  \n",
      "  inflating: SECTION_DATA_TABLE.csv  \n",
      "  inflating: SECTION_HISTORY_DATA_TABLE.csv  \n",
      "  inflating: STUDENT_DATA_TABLE.csv  \n",
      "  inflating: ZIPCODE_DATA_TABLE.csv  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ./data/student\n",
    "unzip -o student.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58ed336",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/student/\n",
    "hdfs dfs -mkdir -p student\n",
    "hdfs dfs -put -f *.csv student\n",
    "\n",
    "rm -rf *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84cdb11",
   "metadata": {},
   "source": [
    "---\n",
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d4da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4882cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 17:44:28,578 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-02-20 17:44:31,714 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.debug.maxToStringFields', 100) \\\n",
    "    .config('spark.executor.memory', '2g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc80e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 4\n",
    "NUM_PARTITIONS = 3\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set('spark.sql.legacy.timeParserPolicy', 'LEGACY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2e922",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201eac20",
   "metadata": {},
   "source": [
    "# Stduent schema CSV \n",
    "\n",
    "* [SparkSQL CSV Files](https://spark.apache.org/docs/latest/sql-data-sources-csv.html)\n",
    "\n",
    "> Spark SQL provides spark.read().csv(\"file_name\") to read a file or directory of files in CSV format into Spark DataFrame, and dataframe.write().csv(\"path\") to write to a CSV file. Function option() can be used to customize the behavior of reading or writing.\n",
    "\n",
    "[SparkSession.read()](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/SparkSession.html#read--) returns [DataFrameReader](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html) instance which has [option](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-boolean-) method by which we can specify CSV options.\n",
    "\n",
    "The options are listed in [Data Source Option](https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b687a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- COST: integer (nullable = true)\n",
      " |-- PREREQUISITE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------+----------------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|COURSE_NO|DESCRIPTION                 |COST|PREREQUISITE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------+----------------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|10       |Technology Concepts         |1195|null        |DSCHERER  |2007-03-29  |ARISCHER   |2007-04-05   |\n",
      "|20       |Intro to Information Systems|1195|null        |DSCHERER  |2007-03-29  |ARISCHER   |2007-04-05   |\n",
      "|25       |Intro to Programming        |1195|140         |DSCHERER  |2007-03-29  |ARISCHER   |2007-04-05   |\n",
      "+---------+----------------------------+----+------------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/COURSE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "course.printSchema()\n",
    "course.createOrReplaceTempView(\"course\")\n",
    "course.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a4709ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- REVENUE: integer (nullable = true)\n",
      " |-- COURSE_FEE: integer (nullable = true)\n",
      " |-- NUM_ENROLLED: integer (nullable = true)\n",
      " |-- NUM_OF_SECTIONS: integer (nullable = true)\n",
      "\n",
      "+---------+-------+----------+------------+---------------+\n",
      "|COURSE_NO|REVENUE|COURSE_FEE|NUM_ENROLLED|NUM_OF_SECTIONS|\n",
      "+---------+-------+----------+------------+---------------+\n",
      "|10       |1195   |1195      |1           |1              |\n",
      "|20       |10755  |1195      |9           |4              |\n",
      "|25       |53775  |1195      |45          |8              |\n",
      "+---------+-------+----------+------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course_revenue = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/COURSE_REVENUE_DATA_TABLE.csv\")\n",
    "\n",
    "course_revenue.printSchema()\n",
    "course_revenue.createOrReplaceTempView(\"course_revenue\")\n",
    "course_revenue.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "963ed672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- SECTION_NO: integer (nullable = true)\n",
      " |-- START_DATE_TIME: date (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- CAPACITY: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|SECTION_ID|COURSE_NO|SECTION_NO|START_DATE_TIME|LOCATION|INSTRUCTOR_ID|CAPACITY|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|        79|      350|         3|     2007-04-14|    L509|          107|      25|  CBRENNAN|  2007-01-02|   CBRENNAN|   2007-01-02|\n",
      "|        80|       10|         2|     2007-04-24|    L214|          102|      15|  CBRENNAN|  2007-01-02|   CBRENNAN|   2007-01-02|\n",
      "|        81|       20|         2|     2007-07-24|    L210|          103|      15|  CBRENNAN|  2007-01-02|   CBRENNAN|   2007-01-02|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/SECTION_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"START_DATE_TIME\", to_date(col('START_DATE_TIME'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "section.printSchema()\n",
    "section.createOrReplaceTempView(\"section\")\n",
    "section.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eecc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|INSTRUCTOR_ID|SALUTATION|FIRST_NAME|LAST_NAME|STREET_ADDRESS|  ZIP|     PHONE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|          101|        Mr|   Fernand|    Hanks| 100 East 87th|10015|2125551212|  ESILVEST|  2007-01-02|   ESILVEST|   2007-01-02|\n",
      "|          102|        Mr|       Tom|   Wojick|518 West 120th|10025|2125551212|  ESILVEST|  2007-01-02|   ESILVEST|   2007-01-02|\n",
      "|          103|        Ms|      Nina|  Schorin|210 West 101st|10025|2125551212|  ESILVEST|  2007-01-02|   ESILVEST|   2007-01-02|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructor = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/INSTRUCTOR_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "instructor.printSchema()\n",
    "instructor.createOrReplaceTempView(\"instructor\")\n",
    "instructor.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82e94d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- EMPLOYER: string (nullable = true)\n",
      " |-- REGISTRATION_DATE: date (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SALUTATION|FIRST_NAME|LAST_NAME|    STREET_ADDRESS|  ZIP|       PHONE|       EMPLOYER|REGISTRATION_DATE| CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|       167|       Mr.|       Jim|     Joas|   53-33 192nd St.|11365|718-555-5555|     Gaum, Inc.|       2007-02-02|BROSENZWEIG|  2007-02-02|   BROSENZW|   2007-02-02|\n",
      "|       168|       Ms.|     Sally|     Naso|      812 79th St.| 7047|201-555-5555|Motors National|       2007-02-02|BROSENZWEIG|  2007-02-02|   BROSENZW|   2007-02-02|\n",
      "|       169|       Mr.|    Frantz|   McLean|23-08 Newtown Ave.|11102|718-555-5555|Guenther Miller|       2007-02-02|BROSENZWEIG|  2007-02-02|   BROSENZW|   2007-02-02|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/STUDENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"REGISTRATION_DATE\", to_date(col('REGISTRATION_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"CREATED_DATE\",      to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\",     to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "student.cache()\n",
    "student.printSchema()\n",
    "student.createOrReplaceTempView(\"student\")\n",
    "student.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc1b01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- ENROLL_DATE: string (nullable = true)\n",
      " |-- FINAL_GRADE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|ENROLL_DATE|FINAL_GRADE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|       215|       146|  13-FEB-07|       null|  DSCHERER|  2007-12-14|   BROSENZW|   2007-01-05|\n",
      "|       215|       156|  13-FEB-07|       null|  DSCHERER|  2007-12-14|   BROSENZW|   2007-01-05|\n",
      "|       216|       154|  13-FEB-07|       null|  DSCHERER|  2007-12-14|   BROSENZW|   2007-01-05|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 63:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "enrollment = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/ENROLLMENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "enrollment.cache()\n",
    "enrollment.printSchema()\n",
    "enrollment.createOrReplaceTempView(\"enrollment\")\n",
    "enrollment.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85e1ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- GRADE_CODE_OCCURRENCE: integer (nullable = true)\n",
      " |-- NUMERIC_GRADE: integer (nullable = true)\n",
      " |-- COMMENTS: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|GRADE_TYPE_CODE|GRADE_CODE_OCCURRENCE|NUMERIC_GRADE|COMMENTS|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|       111|       133|             PA|                    6|           80|    null|  CBRENNAN|  2007-02-11|     JAYCAF|   2007-02-11|\n",
      "|       111|       133|             PA|                    7|           70|    null|  CBRENNAN|  2007-02-11|     JAYCAF|   2007-02-11|\n",
      "|       111|       133|             PA|                    8|           70|    null|  CBRENNAN|  2007-02-11|     JAYCAF|   2007-02-11|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/GRADE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "grade.printSchema()\n",
    "grade.createOrReplaceTempView(\"grade\")\n",
    "grade.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fbc5d",
   "metadata": {},
   "source": [
    "Need to make sure 31-DEC-98 is converted to 1998-12-31, not 2098-12-31.\n",
    "\n",
    "* [spark to_date function - how to convert 31-DEC-98 to 1998-12-31 not 2098-12-31](https://stackoverflow.com/questions/71182230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039a2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|GRADE_TYPE_CODE|DESCRIPTION|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|             FI|      Final|  MCAFFREY|  1998-12-31|   MCAFFREY|   1998-12-31|\n",
      "|             HM|   Homework|  MCAFFREY|  1998-12-31|   MCAFFREY|   1998-12-31|\n",
      "|             MT|    Midterm|  MCAFFREY|  1998-12-31|   MCAFFREY|   1998-12-31|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade_type = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/GRADE_TYPE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "grade_type.printSchema()\n",
    "grade_type.createOrReplaceTempView(\"grade_type\")\n",
    "grade_type.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81fcc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|  ZIP|            CITY|STATE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|11101|Long Island City|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11102|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11103|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipcode = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/ZIPCODE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "zipcode.printSchema()\n",
    "zipcode.createOrReplaceTempView(\"zipcode\")\n",
    "zipcode.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ddaeb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      "\n",
      "+-----------+------+------+---------+\n",
      "|EMPLOYEE_ID|  NAME|SALARY|    TITLE|\n",
      "+-----------+------+------+---------+\n",
      "|          1|  John|  1000|  Analyst|\n",
      "|          2|  Mary|  2000|  Manager|\n",
      "|          3|Stella|  5000|President|\n",
      "+-----------+------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"student/EMPLOYEE_DATA_TABLE.csv\")\n",
    "\n",
    "employee.printSchema()\n",
    "employee.createOrReplaceTempView(\"employee\")\n",
    "employee.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea51c65f",
   "metadata": {},
   "source": [
    "---\n",
    "# Analytics Functions\n",
    "\n",
    "The general syntax of analytical functions is **```analytic_function([arguments]) OVER (analytic_clause)```**\n",
    "\n",
    "```OVER``` keyword indicates that the function operates after the results of the FROM, WHERE, GROUP BY, and HAVING clauses have been formed.\n",
    "\n",
    "**analytic_clause** can contain three other clauses: ```QUERY_PARTITIONING```, ```ORDER_BY```, or ```WINDOWING```.<br>\n",
    "```[query_partition_clause] [order_by_clause [windowing_clause]]```\n",
    "\n",
    "<img src=\"./image/analytics_function_query_execution_steps.jpg\" align=\"left\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f4fe0",
   "metadata": {},
   "source": [
    "---\n",
    "# Analytcis function vs GROUP BY\n",
    "\n",
    "* [How X in SELECT X, AGG(Z) OVER (PARTITION X) is handled in analytics SQL](https://stackoverflow.com/questions/71201623/sql-how-x-in-select-x-aggz-over-partition-x-is-handled-in-analytics-sql)\n",
    "\n",
    "The SQL engine finds X column in SELECT statement, and check if it exists in the PARITION BY clause. If exists, the value of the X is applied in the PARTITION BY part. This is similar to the correlated subquery and GROUP BY SQL ```SELECT X, AGG(Z) FROM T GROUP BY X```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fe956d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "|grade_type_code|maximum|minimum|mean |var  |std |cnt|\n",
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "|FI             |99     |76     |85.77|46.99|6.86|205|\n",
      "|HM             |99     |70     |86.12|67.27|8.2 |798|\n",
      "|MT             |99     |76     |87.08|43.15|6.57|204|\n",
      "|PA             |99     |70     |86.32|56.43|7.51|394|\n",
      "|PJ             |99     |76     |87.0 |48.2 |6.94|21 |\n",
      "|QZ             |99     |73     |86.75|59.97|7.74|382|\n",
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    grade_type_code,\n",
    "    MAX(numeric_grade) OVER (PARTITION BY grade_type_code) as maximum,\n",
    "    MIN(numeric_grade) OVER (PARTITION BY grade_type_code) as minimum,\n",
    "    ROUND(AVG(numeric_grade) OVER (PARTITION BY grade_type_code),2) as mean,\n",
    "    ROUND(VARIANCE(numeric_grade) OVER (PARTITION BY grade_type_code),2) as var,\n",
    "    ROUND(STDDEV(numeric_grade) OVER (PARTITION BY grade_type_code),2) as std,\n",
    "    COUNT(numeric_grade) OVER (PARTITION BY grade_type_code) as cnt\n",
    "FROM\n",
    "    grade\n",
    "ORDER BY\n",
    "    grade_type_code\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9a1a58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "|grade_type_code|maximum|minimum|mean |var  |std |cnt|\n",
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "|FI             |99     |76     |85.77|46.99|6.86|205|\n",
      "|HM             |99     |70     |86.12|67.27|8.2 |798|\n",
      "|MT             |99     |76     |87.08|43.15|6.57|204|\n",
      "|PA             |99     |70     |86.32|56.43|7.51|394|\n",
      "|PJ             |99     |76     |87.0 |48.2 |6.94|21 |\n",
      "|QZ             |99     |73     |86.75|59.97|7.74|382|\n",
      "+---------------+-------+-------+-----+-----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    grade_type_code,\n",
    "    MAX(numeric_grade) as maximum,\n",
    "    MIN(numeric_grade) as minimum,\n",
    "    ROUND(AVG(numeric_grade),2) as mean,\n",
    "    ROUND(VARIANCE(numeric_grade), 2) as var,\n",
    "    ROUND(STDDEV(numeric_grade), 2) as std,\n",
    "    COUNT(*) as cnt\n",
    "FROM\n",
    "    grade\n",
    "GROUP BY\n",
    "    grade_type_code\n",
    "ORDER BY \n",
    "    grade_type_code\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b4e10",
   "metadata": {},
   "source": [
    "---\n",
    "# Pivot\n",
    "\n",
    "Transform from Long/Stack Format to Wide/Unstack Format. \n",
    "\n",
    "1. Find the ID (keys) that identifyes an class instance that will be a row in Wide Format.\n",
    "2. Create (ID, attribute, value) Long Format.\n",
    "3. ```PIVOT (FOR attribute IN (<attributes>))```\n",
    "\n",
    "\n",
    "* [PIVOT Clause](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-pivot.html)\n",
    "\n",
    "## Syntax\n",
    "```\n",
    "PIVOT (\n",
    "    aggregate_expression(value) [ AS aggregate_expression_alias ]\n",
    "    [ , ... ]   /* Continue with , for multipel aggregations */\n",
    "    FOR attributes IN ( \n",
    "        attribute_list \n",
    "    )\n",
    ") \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eade83",
   "metadata": {},
   "source": [
    "Find the number of classes starting at each location.\n",
    "\n",
    "1. Find the ```location``` as **ID**.\n",
    "2. Create (ID, attribute, value) Long Format table.\n",
    "3. PIVOT (Long to Wide Transformation) that generates rows where each row is an class instance with attributes.\n",
    "\n",
    "\n",
    "<img src=\"./image/pivot.jpg\" align=\"left\" width=600/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20add6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+\n",
      "|location|day_text|day_num|\n",
      "+--------+--------+-------+\n",
      "|    H310|     Tue|      3|\n",
      "|    L206|     Tue|      3|\n",
      "|    L210|     Tue|      3|\n",
      "|    L210|     Mon|      2|\n",
      "|    L210|     Tue|      3|\n",
      "|    L210|     Fri|      6|\n",
      "|    L210|     Sat|      7|\n",
      "|    L210|     Tue|      3|\n",
      "|    L210|     Sat|      7|\n",
      "|    L210|     Wed|      4|\n",
      "|    L210|     Mon|      2|\n",
      "|    L210|     Sun|      1|\n",
      "|    L211|     Thu|      5|\n",
      "|    L211|     Tue|      3|\n",
      "|    L211|     Sat|      7|\n",
      "|    L214|     Sat|      7|\n",
      "|    L214|     Fri|      6|\n",
      "|    L214|     Thu|      5|\n",
      "|    L214|     Sun|      1|\n",
      "|    L214|     Thu|      5|\n",
      "+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    location,\n",
    "    date_format(start_date_time, \"EEE\") AS day_text,\n",
    "    dayofweek(start_date_time) AS day_num\n",
    "FROM\n",
    "    section\n",
    "ORDER BY location\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a17fc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+----+----+----+----+----+\n",
      "|location| MON| TUE| WED| THU| FRI| SAT| SUN|\n",
      "+--------+----+----+----+----+----+----+----+\n",
      "|    H310|null|   1|null|null|null|null|null|\n",
      "|    L206|null|   1|null|null|null|null|null|\n",
      "|    L210|   2|   3|   1|null|   1|   2|   1|\n",
      "|    L211|null|   1|null|   1|null|   1|null|\n",
      "|    L214|   2|   2|null|   2|   1|   4|   4|\n",
      "|    L500|   1|   1|null|null|null|null|null|\n",
      "|    L507|   4|   3|   3|null|   1|   3|   1|\n",
      "|    L509|   4|   5|   3|   2|   1|   4|   6|\n",
      "|    L511|null|null|null|null|null|   1|null|\n",
      "|    M200|   1|null|null|null|null|null|null|\n",
      "|    M311|   1|null|null|null|null|   1|   1|\n",
      "|    M500|null|null|null|null|null|   1|null|\n",
      "+--------+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH location_day_cnt AS (\n",
    "    SELECT\n",
    "        location,\n",
    "        upper(date_format(start_date_time, \"EEE\")) AS day,\n",
    "        COUNT(*) AS cnt\n",
    "    FROM\n",
    "        section\n",
    "    GROUP BY\n",
    "        location, upper(date_format(start_date_time, \"EEE\"))\n",
    "    ORDER BY location\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    location_day_cnt\n",
    "PIVOT (\n",
    "    SUM(cnt)\n",
    "    FOR day IN (\n",
    "        'MON' AS MON,\n",
    "        'TUE' AS TUE,\n",
    "        'WED' AS WED,\n",
    "        'THU' AS THU,\n",
    "        'FRI' AS FRI,\n",
    "        'SAT' AS SAT,\n",
    "        'SUN' AS SUN\n",
    "    )\n",
    ")\n",
    "ORDER BY\n",
    "    location\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ab520",
   "metadata": {},
   "source": [
    "---\n",
    "# MAX/FIRST_VALUE\n",
    "\n",
    "Student with best grade in (course, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a50bd",
   "metadata": {},
   "source": [
    "### GROUP BY approach\n",
    "\n",
    "1. Create a joined table of (grade, section).\n",
    "2. GROUP BY (course_no, section_id) and get MAX(numeric_grade).\n",
    "3. Annotate with course.description, student.first_name, student.last_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfe1c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:=============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+----------+-----------------+\n",
      "|course_no|         course_name|section_id|best_grade|     student_name|\n",
      "+---------+--------------------+----------+----------+-----------------+\n",
      "|       10| Technology Concepts|        80|        91|      Jeff Runyan|\n",
      "|       20|Intro to Informat...|        81|        92|    Laetia Enison|\n",
      "|       20|Intro to Informat...|        83|        99|Daniel Wicelinski|\n",
      "|       20|Intro to Informat...|        84|        99|        J. Segall|\n",
      "|       25|Intro to Programming|        85|        92|     Gerard Biers|\n",
      "|       25|Intro to Programming|        86|        99|   Jeffrey Citron|\n",
      "|       25|Intro to Programming|        87|        99|  Pierre Radicola|\n",
      "|       25|Intro to Programming|        89|        99|        M. Diokno|\n",
      "|       25|Intro to Programming|        90|        92|    Eric Da Silva|\n",
      "|       25|Intro to Programming|        91|        77|     Jose Benitez|\n",
      "|       25|Intro to Programming|        92|        92|    Frank Bunnell|\n",
      "|      100|    Hands-On Windows|       141|        99|      Regina Bose|\n",
      "|      100|    Hands-On Windows|       142|        85|   Peggy Noviello|\n",
      "|      100|    Hands-On Windows|       143|        92|   Monica Waldman|\n",
      "|      100|    Hands-On Windows|       145|        92|     Jose Benitez|\n",
      "|      120|Intro to Java Pro...|       146|        88|    Evan Fielding|\n",
      "|      120|Intro to Java Pro...|       147|        99|     Lloyd Kellam|\n",
      "|      120|Intro to Java Pro...|       148|        88|    Jean Griffith|\n",
      "|      120|Intro to Java Pro...|       150|        99|   Michael Carcia|\n",
      "|      120|Intro to Java Pro...|       151|        92|        Hedy Naso|\n",
      "+---------+--------------------+----------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH course_section_max_grade AS (\n",
    "    SELECT\n",
    "        s.course_no,\n",
    "        g.section_id,\n",
    "        MAX(g.numeric_grade) as best_grade\n",
    "    FROM\n",
    "        grade g\n",
    "        INNER JOIN section s ON s.section_id = g.section_id\n",
    "    WHERE\n",
    "        g.grade_type_code = 'FI'\n",
    "    GROUP BY\n",
    "        s.course_no,\n",
    "        g.section_id\n",
    "    ORDER BY\n",
    "        s.course_no,\n",
    "        g.section_id\n",
    ")\n",
    "SELECT\n",
    "    m.course_no,\n",
    "    (SELECT MAX(c.description) FROM course c WHERE c.course_no = m.course_no) AS course_name,\n",
    "    m.section_id,\n",
    "    m.best_grade,\n",
    "    concat(t.first_name, ' ', t.last_name) AS student_name\n",
    "FROM\n",
    "    course_section_max_grade m\n",
    "    INNER JOIN grade g \n",
    "        ON g.section_id = m.section_id \n",
    "        AND g.numeric_grade = m.best_grade\n",
    "    INNER JOIN student t\n",
    "        ON t.student_id = g.student_id\n",
    "WHERE\n",
    "    g.grade_type_code = 'FI'\n",
    "ORDER BY \n",
    "    m.course_no,\n",
    "    m.section_id\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcfa8e",
   "metadata": {},
   "source": [
    "### Analytics approach\n",
    "\n",
    "1. Create a joined table of (course, section, grade).\n",
    "2. Order DESC by grade in each partition (course_no, section_id) and pick the FIRST_VLAUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae2e83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 195:============================>                           (6 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+----------+----------+-----------------+\n",
      "|course_no|course_name                 |section_id|best_grade|best_student     |\n",
      "+---------+----------------------------+----------+----------+-----------------+\n",
      "|10       |Technology Concepts         |80        |91        |Jeff Runyan      |\n",
      "|20       |Intro to Information Systems|81        |92        |Laetia Enison    |\n",
      "|20       |Intro to Information Systems|81        |92        |Laetia Enison    |\n",
      "|20       |Intro to Information Systems|81        |92        |Laetia Enison    |\n",
      "|20       |Intro to Information Systems|83        |99        |Daniel Wicelinski|\n",
      "|20       |Intro to Information Systems|83        |99        |Daniel Wicelinski|\n",
      "|20       |Intro to Information Systems|84        |99        |J. Segall        |\n",
      "|20       |Intro to Information Systems|84        |99        |J. Segall        |\n",
      "|25       |Intro to Programming        |85        |92        |Gerard Biers     |\n",
      "|25       |Intro to Programming        |85        |92        |Gerard Biers     |\n",
      "|25       |Intro to Programming        |85        |92        |Gerard Biers     |\n",
      "|25       |Intro to Programming        |85        |92        |Gerard Biers     |\n",
      "|25       |Intro to Programming        |85        |92        |Gerard Biers     |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |86        |99        |Jeffrey Citron   |\n",
      "|25       |Intro to Programming        |87        |99        |Pierre Radicola  |\n",
      "+---------+----------------------------+----------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH course_section_grade AS (\n",
    "    SELECT\n",
    "        c.course_no AS course_no,\n",
    "        c.description AS course_name,\n",
    "        g.section_id AS section_id,\n",
    "        g.numeric_grade as grade,\n",
    "        t.student_id,\n",
    "        (t.first_name || ' ' || t.last_name) as student_name\n",
    "    FROM\n",
    "        grade g\n",
    "        INNER JOIN section s\n",
    "            ON s.section_id = g.section_id\n",
    "        INNER JOIN course c\n",
    "            ON s.course_no = c.course_no\n",
    "        INNER JOIN student t\n",
    "            ON t.student_id = g.student_id\n",
    "    WHERE\n",
    "        g.grade_type_code = 'FI'\n",
    "    ORDER BY\n",
    "        c.course_no,\n",
    "        g.section_id,\n",
    "        g.numeric_grade\n",
    ")\n",
    "SELECT     \n",
    "    course_no,\n",
    "    course_name,\n",
    "    section_id,\n",
    "    FIRST_VALUE(grade) OVER (PARTITION BY course_no, section_id ORDER BY grade DESC) as best_grade,\n",
    "    FIRST_VALUE(student_name) OVER (PARTITION BY course_no, section_id ORDER BY grade DESC) as best_student\n",
    "FROM\n",
    "    course_section_grade csg\n",
    "ORDER BY\n",
    "    course_no,\n",
    "    section_id\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c041ac",
   "metadata": {},
   "source": [
    "---\n",
    "# Rank/DENSE_RANK\n",
    "\n",
    "The RANK() function assigns a rank to each row based on a provided column. \n",
    "\n",
    "```RANK() OVER (PARTITION BY columns ORDER BY columns ASC|DESC)```\n",
    "\n",
    "Rank of students based on the final grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40e69a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+----------+-------------------+-----+-----+-------+------+\n",
      "|course_no|course_name                 |section_id|student_name       |grade|delta|ranking|rownum|\n",
      "+---------+----------------------------+----------+-------------------+-----+-----+-------+------+\n",
      "|10       |Technology Concepts         |80        |Jeff Runyan        |91   |NA   |1      |1     |\n",
      "|20       |Intro to Information Systems|83        |Daniel Wicelinski  |99   |NA   |1      |1     |\n",
      "|20       |Intro to Information Systems|84        |J. Segall          |99   |0    |1      |2     |\n",
      "|20       |Intro to Information Systems|81        |Laetia Enison      |92   |7    |2      |3     |\n",
      "|20       |Intro to Information Systems|81        |J. Landry          |91   |1    |3      |4     |\n",
      "|20       |Intro to Information Systems|83        |Michael Carcia     |90   |1    |4      |5     |\n",
      "|20       |Intro to Information Systems|84        |Roy Limate         |88   |2    |5      |6     |\n",
      "|20       |Intro to Information Systems|81        |Z.A. Scrittorale   |83   |5    |6      |7     |\n",
      "|25       |Intro to Programming        |86        |Jeffrey Citron     |99   |NA   |1      |1     |\n",
      "|25       |Intro to Programming        |87        |Pierre Radicola    |99   |0    |1      |2     |\n",
      "|25       |Intro to Programming        |89        |M. Diokno          |99   |0    |1      |3     |\n",
      "|25       |Intro to Programming        |87        |Lorrane Velasco    |92   |7    |2      |4     |\n",
      "|25       |Intro to Programming        |85        |Gerard Biers       |92   |0    |2      |5     |\n",
      "|25       |Intro to Programming        |89        |Fred Crocitto      |92   |0    |2      |6     |\n",
      "|25       |Intro to Programming        |89        |Walter Boremmann   |92   |0    |2      |7     |\n",
      "|25       |Intro to Programming        |90        |Eric Da Silva      |92   |0    |2      |8     |\n",
      "|25       |Intro to Programming        |92        |Frank Bunnell      |92   |0    |2      |9     |\n",
      "|25       |Intro to Programming        |87        |Melvina Chamnonkool|91   |1    |3      |10    |\n",
      "|25       |Intro to Programming        |89        |Bessie Heedles     |91   |0    |3      |11    |\n",
      "|25       |Intro to Programming        |90        |Hiedi Lopez        |91   |0    |3      |12    |\n",
      "+---------+----------------------------+----------+-------------------+-----+-----+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH course_section_grade AS (\n",
    "    SELECT\n",
    "        c.course_no AS course_no,\n",
    "        c.description AS course_name,\n",
    "        g.section_id AS section_id,\n",
    "        g.numeric_grade as grade,\n",
    "        t.student_id,\n",
    "        (t.first_name || ' ' || t.last_name) as student_name\n",
    "    FROM\n",
    "        grade g\n",
    "        INNER JOIN section s\n",
    "            ON s.section_id = g.section_id\n",
    "        INNER JOIN course c\n",
    "            ON s.course_no = c.course_no\n",
    "        INNER JOIN student t\n",
    "            ON t.student_id = g.student_id\n",
    "    WHERE\n",
    "        g.grade_type_code = 'FI'\n",
    "    ORDER BY\n",
    "        c.course_no,\n",
    "        g.section_id,\n",
    "        g.numeric_grade\n",
    ")\n",
    "SELECT\n",
    "    course_no,\n",
    "    course_name,\n",
    "    section_id,\n",
    "    student_name,\n",
    "    grade,\n",
    "    NVL(LAG(grade) OVER (PARTITION BY course_no ORDER BY grade DESC) - grade, 'NA') AS delta, \n",
    "    DENSE_RANK() OVER (PARTITION BY course_no ORDER BY grade DESC) AS ranking,\n",
    "    ROW_NUMBER() OVER (PARTITION BY course_no ORDER BY grade DESC) AS rownum\n",
    "FROM\n",
    "    course_section_grade\n",
    "ORDER BY\n",
    "    course_no,\n",
    "    ranking,\n",
    "    rownum\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6758a",
   "metadata": {},
   "source": [
    "---\n",
    "# NTILE\n",
    "\n",
    "```NTILE(number_of_bins) OVER (PARTITION BY columns ORDER BY columns [DESC|ASC]```\n",
    "\n",
    "Top 5% (20 TILES) highest grade student in the entire students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f053c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 14:55:57,631 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+--------+\n",
      "|student_name          |grade|quantile|\n",
      "+----------------------+-----+--------+\n",
      "|Daniel Wicelinski     |99   |1       |\n",
      "|J. Segall             |99   |1       |\n",
      "|Regina Bose           |99   |1       |\n",
      "|Yvonne Williams       |99   |1       |\n",
      "|Salewa Zuckerberg     |99   |1       |\n",
      "|Daniel Wicelinski     |99   |1       |\n",
      "|Judy Cahouet          |99   |1       |\n",
      "|Catherine Frangopoulos|99   |1       |\n",
      "|Jeffrey Citron        |99   |1       |\n",
      "|Pierre Radicola       |99   |1       |\n",
      "|M. Diokno             |99   |1       |\n",
      "|Arlyne Sheppard       |76   |20      |\n",
      "|Janet Jung            |76   |20      |\n",
      "|Daniel Ordes          |76   |20      |\n",
      "|Charles Caro          |76   |20      |\n",
      "|Anil Kulina           |76   |20      |\n",
      "|James Reed            |76   |20      |\n",
      "|Angel Cook            |76   |20      |\n",
      "|Ricardo Kurtz         |76   |20      |\n",
      "|Catherine Frangopoulos|76   |20      |\n",
      "+----------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH course_section_grade AS (\n",
    "    SELECT\n",
    "        c.course_no AS course_no,\n",
    "        c.description AS course_name,\n",
    "        g.section_id AS section_id,\n",
    "        g.numeric_grade as grade,\n",
    "        t.student_id,\n",
    "        (t.first_name || ' ' || t.last_name) as student_name\n",
    "    FROM\n",
    "        grade g\n",
    "        INNER JOIN section s\n",
    "            ON s.section_id = g.section_id\n",
    "        INNER JOIN course c\n",
    "            ON s.course_no = c.course_no\n",
    "        INNER JOIN student t\n",
    "            ON t.student_id = g.student_id\n",
    "    WHERE\n",
    "        g.grade_type_code = 'FI'\n",
    "    ORDER BY\n",
    "        c.course_no,\n",
    "        g.section_id,\n",
    "        g.numeric_grade\n",
    ")\n",
    "SELECT \n",
    "    *\n",
    "FROM (\n",
    "    SELECT\n",
    "        student_name,\n",
    "        grade,\n",
    "        NTILE(20) OVER (ORDER BY grade DESC) AS quantile\n",
    "    FROM\n",
    "        course_section_grade\n",
    ") q\n",
    "WHERE \n",
    "    q.quantile = 1 OR q.quantile = 20\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30965aa",
   "metadata": {},
   "source": [
    "# MODE\n",
    "\n",
    "The value that occurs with the greatest frequency. ```STATS_MODE(expr)``` does not exist in SparkSQL.\n",
    "\n",
    "Find the most frequent numeric_grade for each grade_type_code in the grade table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "03ef75b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+-----------+\n",
      "|grade_type_code|numeric_grade|occurrences|\n",
      "+---------------+-------------+-----------+\n",
      "|FI             |76           |28         |\n",
      "|FI             |77           |23         |\n",
      "|FI             |83           |18         |\n",
      "|FI             |84           |18         |\n",
      "|FI             |85           |25         |\n",
      "|FI             |88           |22         |\n",
      "|FI             |90           |16         |\n",
      "|FI             |91           |16         |\n",
      "|FI             |92           |20         |\n",
      "|FI             |99           |19         |\n",
      "|HM             |70           |2          |\n",
      "|HM             |71           |2          |\n",
      "|HM             |72           |4          |\n",
      "|HM             |73           |23         |\n",
      "|HM             |74           |44         |\n",
      "|HM             |75           |39         |\n",
      "|HM             |76           |36         |\n",
      "|HM             |77           |21         |\n",
      "|HM             |78           |6          |\n",
      "|HM             |79           |2          |\n",
      "+---------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    grade_type_code,\n",
    "    numeric_grade AS numeric_grade,\n",
    "    COUNT(numeric_grade) AS occurrences\n",
    "FROM\n",
    "    grade\n",
    "GROUP BY \n",
    "    grade_type_code, numeric_grade\n",
    "ORDER BY\n",
    "    grade_type_code,\n",
    "    numeric_grade\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "da3f1c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|grade_type_code|mode|\n",
      "+---------------+----+\n",
      "|FI             |28  |\n",
      "|HM             |59  |\n",
      "|MT             |28  |\n",
      "|PA             |31  |\n",
      "|PJ             |4   |\n",
      "|QZ             |37  |\n",
      "+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH mode_per_grade_type AS (\n",
    "    SELECT\n",
    "        grade_type_code,\n",
    "        numeric_grade AS numeric_grade,\n",
    "        COUNT(numeric_grade) AS occurrences\n",
    "    FROM\n",
    "        grade\n",
    "    GROUP BY \n",
    "        grade_type_code, numeric_grade\n",
    "    ORDER BY\n",
    "        grade_type_code,\n",
    "        numeric_grade\n",
    ")\n",
    "SELECT\n",
    "    grade_type_code,\n",
    "    MAX(occurrences) mode\n",
    "FROM\n",
    "    mode_per_grade_type\n",
    "GROUP BY \n",
    "    grade_type_code\n",
    "ORDER BY\n",
    "    grade_type_code,\n",
    "    mode DESC\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce65c99",
   "metadata": {},
   "source": [
    "---\n",
    "# Windowing\n",
    "```\n",
    "SELECT\n",
    "    <Analytics Function> OVER (\n",
    "        PARTITION BY <partition_column>\n",
    "        ORDER BY <order_column>\n",
    "        ROWS BETWEEN <start> AND <end>\n",
    "    ) AS <name>\n",
    "FROM\n",
    "    <TABLE> \n",
    "```\n",
    "\n",
    "ORDER BY in a windowing clause is a mandatory clause that determines the order in which the rows are sorted. Based on this order, the starting and ending points of the window are defined.\n",
    "\n",
    "### Start/End of the window\n",
    "\n",
    "* UNBOUNDED PRECEDING :<br>\n",
    "The window starts at the first row of the partition, or the whole result set if no partitioning clause is used. Only available for start points.\n",
    "* UNBOUNDED FOLLOWING :<br>\n",
    "The window ends at the last row of the partition, or the whole result set if no partitioning clause is used. Only available for end points.\n",
    "* CURRENT ROW :<br>\n",
    "The window starts or ends at the current row. Can be used as start or end point.\n",
    "* value_expr PRECEDING :  (e.g. 1 PRECEEDING)<br>\n",
    "A physical or logical offset before the current row using a constant or expression that evaluates to a positive numerical value. When used with RANGE, it can also be an interval literal if the order_by_clause uses a DATE column.\n",
    "* value_expr FOLLOWING :  (e.g. 1 FOLLOWING)<br>\n",
    "As above, but an offset after the current row.\n",
    "\n",
    "\n",
    "\n",
    "From the top to the current, ```ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW``` \n",
    "\n",
    "<img src=\"./image/window.jpg\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb365be",
   "metadata": {},
   "source": [
    "## Cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e9893aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------+\n",
      "|course_no|revenue|cumsum|\n",
      "+---------+-------+------+\n",
      "|10       |1195   |1195  |\n",
      "|20       |10755  |11950 |\n",
      "|25       |53775  |65725 |\n",
      "|100      |15535  |81260 |\n",
      "|120      |27485  |108745|\n",
      "|122      |28680  |137425|\n",
      "|124      |9560   |146985|\n",
      "|125      |9560   |156545|\n",
      "|130      |9560   |166105|\n",
      "|132      |2390   |168495|\n",
      "|134      |2390   |170885|\n",
      "|135      |4380   |175265|\n",
      "|140      |17925  |193190|\n",
      "|142      |8365   |201555|\n",
      "|145      |2390   |203945|\n",
      "|146      |3585   |207530|\n",
      "|147      |5975   |213505|\n",
      "|204      |1195   |214700|\n",
      "|230      |15330  |230030|\n",
      "|240      |14235  |244265|\n",
      "+---------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 17:24:05,785 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    course_no,\n",
    "    revenue,\n",
    "    SUM(revenue) OVER (ORDER BY course_no, revenue ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumsum\n",
    "FROM\n",
    "    course_revenue\n",
    "ORDER BY \n",
    "    course_no,\n",
    "    revenue\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1928af9",
   "metadata": {},
   "source": [
    "---\n",
    "# Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a09e1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe597fb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "71a6106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9750"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del spark\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
