{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a609ffd2",
   "metadata": {},
   "source": [
    "# PySpark SparkSQL Group By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37098727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fc02f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e765d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc892c",
   "metadata": {},
   "source": [
    "#  Environemnt Variables\n",
    "\n",
    "## Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR'] = \"/opt/hadoop/hadoop-3.2.2/etc/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21805809",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export HADOOP_CONF_DIR=\"/opt/hadoop/hadoop-3.2.2/etc/hadoop\"\n",
    "ls $HADOOP_CONF_DIR | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ea383",
   "metadata": {},
   "source": [
    "## PYTHONPATH\n",
    "\n",
    "Refer to the **pyspark** modules to load from the ```$SPARK_HOME/python/lib``` in the Spark installation.\n",
    "\n",
    "* [PySpark Getting Started](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
    "\n",
    "> Ensure the SPARK_HOME environment variable points to the directory where the tar file has been extracted. Update PYTHONPATH environment variable such that it can find the PySpark and Py4J under SPARK_HOME/python/lib. One example of doing this is shown below:\n",
    "\n",
    "```\n",
    "export PYTHONPATH=$(ZIPS=(\"$SPARK_HOME\"/python/lib/*.zip); IFS=:; echo \"${ZIPS[*]}\"):$PYTHONPATH\n",
    "```\n",
    "\n",
    "Alternatively install **pyspark** with pip or conda locally which installs the Spark runtime libararies (for standalone).\n",
    "\n",
    "* [Can PySpark work without Spark?](https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark)\n",
    "\n",
    "> As of v2.2, executing pip install pyspark will install Spark. If you're going to use Pyspark it's clearly the simplest way to get started. On my system Spark is installed inside my virtual environment (miniconda) at lib/python3.6/site-packages/pyspark/jars  \n",
    "> PySpark has a Spark installation installed. If installed through pip3, you can find it with pip3 show pyspark. Ex. for me it is at ~/.local/lib/python3.8/site-packages/pyspark. This is a standalone configuration so it can't be used for managing clusters like a full Spark installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbbd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYTHONPATH'] = \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip:/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "sys.path.extend([\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/py4j-0.10.9-src.zip\",\n",
    "    \"/opt/spark/spark-3.1.2/python/lib/pyspark.zip\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318e32e",
   "metadata": {},
   "source": [
    "## PySpark packages\n",
    "\n",
    "Execute after the PYTHONPATH setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc37261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    avg,\n",
    "    stddev,\n",
    "    isnan,\n",
    "    to_date,\n",
    "    to_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b9883",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Student schema from [Oracle SQL by Example](https://learning.oreilly.com/library/view/oracle-sql-by/9780137047345/ch06.html) located in ```./data/student```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a5c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  student.zip\n",
      "  inflating: COURSE_DATA_TABLE.csv   \n",
      "  inflating: COURSE_REVENUE_DATA_TABLE.csv  \n",
      "  inflating: EMPLOYEE_DATA_TABLE.csv  \n",
      "  inflating: ENROLLMENT_DATA_TABLE.csv  \n",
      "  inflating: GRADE_DATA_TABLE.csv    \n",
      "  inflating: GRADE_TYPE_DATA_TABLE.csv  \n",
      "  inflating: INSTRUCTOR_DATA_TABLE.csv  \n",
      "  inflating: SECTION_DATA_TABLE.csv  \n",
      "  inflating: SECTION_HISTORY_DATA_TABLE.csv  \n",
      "  inflating: STUDENT_DATA_TABLE.csv  \n",
      "  inflating: ZIPCODE_DATA_TABLE.csv  \n",
      "COURSE_DATA_TABLE.csv\n",
      "COURSE_REVENUE_DATA_TABLE.csv\n",
      "EMPLOYEE_DATA_TABLE.csv\n",
      "ENROLLMENT_DATA_TABLE.csv\n",
      "GRADE_DATA_TABLE.csv\n",
      "GRADE_TYPE_DATA_TABLE.csv\n",
      "INSTRUCTOR_DATA_TABLE.csv\n",
      "SECTION_DATA_TABLE.csv\n",
      "SECTION_HISTORY_DATA_TABLE.csv\n",
      "STUDENT_DATA_TABLE.csv\n",
      "student.zip\n",
      "ZIPCODE_DATA_TABLE.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ./data/student\n",
    "unzip -o student.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58ed336",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/student/\n",
    "hdfs dfs -mkdir -p student\n",
    "hdfs dfs -put -f *.csv student\n",
    "\n",
    "rm -rf *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84cdb11",
   "metadata": {},
   "source": [
    "---\n",
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d4da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4882cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 14:34:40,651 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-02-19 14:34:45,032 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.debug.maxToStringFields', 100) \\\n",
    "    .config('spark.executor.memory', '2g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc80e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 4\n",
    "NUM_PARTITIONS = 3\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201eac20",
   "metadata": {},
   "source": [
    "# Stduent schema CSV \n",
    "\n",
    "* [SparkSQL CSV Files](https://spark.apache.org/docs/latest/sql-data-sources-csv.html)\n",
    "\n",
    "> Spark SQL provides spark.read().csv(\"file_name\") to read a file or directory of files in CSV format into Spark DataFrame, and dataframe.write().csv(\"path\") to write to a CSV file. Function option() can be used to customize the behavior of reading or writing.\n",
    "\n",
    "[SparkSession.read()](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/SparkSession.html#read--) returns [DataFrameReader](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html) instance which has [option](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-boolean-) method by which we can specify CSV options.\n",
    "\n",
    "The options are listed in [Data Source Option](https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b687a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- COST: integer (nullable = true)\n",
      " |-- PREREQUISITE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|COURSE_NO|         DESCRIPTION|COST|PREREQUISITE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "|       10| Technology Concepts|1195|        null|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "|       20|Intro to Informat...|1195|        null|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "|       25|Intro to Programming|1195|         140|  DSCHERER|  2029-03-07|   ARISCHER|   2005-04-07|\n",
      "+---------+--------------------+----+------------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/COURSE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "course.printSchema()\n",
    "course.createOrReplaceTempView(\"course\")\n",
    "course.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "963ed672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- COURSE_NO: integer (nullable = true)\n",
      " |-- SECTION_NO: integer (nullable = true)\n",
      " |-- START_DATE_TIME: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- CAPACITY: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|SECTION_ID|COURSE_NO|SECTION_NO|START_DATE_TIME|LOCATION|INSTRUCTOR_ID|CAPACITY|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|        79|      350|         3|      14-APR-07|    L509|          107|      25|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "|        80|       10|         2|      24-APR-07|    L214|          102|      15|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "|        81|       20|         2|      24-JUL-07|    L210|          103|      15|  CBRENNAN|  2002-01-07|   CBRENNAN|   2002-01-07|\n",
      "+----------+---------+----------+---------------+--------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/SECTION_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "section.printSchema()\n",
    "section.createOrReplaceTempView(\"section\")\n",
    "section.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8eecc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUCTOR_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|INSTRUCTOR_ID|SALUTATION|FIRST_NAME|LAST_NAME|STREET_ADDRESS|  ZIP|     PHONE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "|          101|        Mr|   Fernand|    Hanks| 100 East 87th|10015|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "|          102|        Mr|       Tom|   Wojick|518 West 120th|10025|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "|          103|        Ms|      Nina|  Schorin|210 West 101st|10025|2125551212|  ESILVEST|  2002-01-07|   ESILVEST|   2002-01-07|\n",
      "+-------------+----------+----------+---------+--------------+-----+----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructor = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/INSTRUCTOR_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "instructor.printSchema()\n",
    "instructor.createOrReplaceTempView(\"instructor\")\n",
    "instructor.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82e94d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SALUTATION: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- STREET_ADDRESS: string (nullable = true)\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- EMPLOYER: string (nullable = true)\n",
      " |-- REGISTRATION_DATE: date (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SALUTATION|FIRST_NAME|LAST_NAME|    STREET_ADDRESS|  ZIP|       PHONE|       EMPLOYER|REGISTRATION_DATE| CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "|       167|       Mr.|       Jim|     Joas|   53-33 192nd St.|11365|718-555-5555|     Gaum, Inc.|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "|       168|       Ms.|     Sally|     Naso|      812 79th St.| 7047|201-555-5555|Motors National|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "|       169|       Mr.|    Frantz|   McLean|23-08 Newtown Ave.|11102|718-555-5555|Guenther Miller|       2002-02-07|BROSENZWEIG|  2002-02-07|   BROSENZW|   2002-02-07|\n",
      "+----------+----------+----------+---------+------------------+-----+------------+---------------+-----------------+-----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/STUDENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"REGISTRATION_DATE\", to_date(col('REGISTRATION_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"CREATED_DATE\",      to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\",     to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "student.cache()\n",
    "student.printSchema()\n",
    "student.createOrReplaceTempView(\"student\")\n",
    "student.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dc1b01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- ENROLL_DATE: string (nullable = true)\n",
      " |-- FINAL_GRADE: integer (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|ENROLL_DATE|FINAL_GRADE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "|       215|       146|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "|       215|       156|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "|       216|       154|  13-FEB-07|       null|  DSCHERER|  2014-12-07|   BROSENZW|   2005-01-07|\n",
      "+----------+----------+-----------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enrollment = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/ENROLLMENT_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "enrollment.cache()\n",
    "enrollment.printSchema()\n",
    "enrollment.createOrReplaceTempView(\"enrollment\")\n",
    "enrollment.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85e1ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STUDENT_ID: integer (nullable = true)\n",
      " |-- SECTION_ID: integer (nullable = true)\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- GRADE_CODE_OCCURRENCE: integer (nullable = true)\n",
      " |-- NUMERIC_GRADE: integer (nullable = true)\n",
      " |-- COMMENTS: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|STUDENT_ID|SECTION_ID|GRADE_TYPE_CODE|GRADE_CODE_OCCURRENCE|NUMERIC_GRADE|COMMENTS|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "|       111|       133|             PA|                    6|           80|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "|       111|       133|             PA|                    7|           70|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "|       111|       133|             PA|                    8|           70|    null|  CBRENNAN|  2011-02-07|     JAYCAF|   2011-02-07|\n",
      "+----------+----------+---------------+---------------------+-------------+--------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/GRADE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"yy-MMM-dd\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"yy-MMM-dd\"))\n",
    "\n",
    "grade.printSchema()\n",
    "grade.createOrReplaceTempView(\"grade\")\n",
    "grade.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fbc5d",
   "metadata": {},
   "source": [
    "Need to make sure 31-DEC-98 is converted to 1998-12-31, not 2098-12-31.\n",
    "\n",
    "* [spark to_date function - how to convert 31-DEC-98 to 1998-12-31 not 2098-12-31](https://stackoverflow.com/questions/71182230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "039a2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRADE_TYPE_CODE: string (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|GRADE_TYPE_CODE|DESCRIPTION|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "|             FI|      Final|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "|             HM|   Homework|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "|             MT|    Midterm|  MCAFFREY|  2098-12-31|   MCAFFREY|   2098-12-31|\n",
      "+---------------+-----------+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade_type = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/GRADE_TYPE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "grade_type.printSchema()\n",
    "grade_type.createOrReplaceTempView(\"grade_type\")\n",
    "grade_type.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81fcc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ZIP: integer (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- CREATED_BY: string (nullable = true)\n",
      " |-- CREATED_DATE: date (nullable = true)\n",
      " |-- MODIFIED_BY: string (nullable = true)\n",
      " |-- MODIFIED_DATE: date (nullable = true)\n",
      "\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|  ZIP|            CITY|STATE|CREATED_BY|CREATED_DATE|MODIFIED_BY|MODIFIED_DATE|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "|11101|Long Island City|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11102|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "|11103|         Astoria|   NY|  AMORRISO|  2007-08-03|   AMORRISO|   2007-11-24|\n",
      "+-----+----------------+-----+----------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipcode = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/ZIPCODE_DATA_TABLE.csv\")\\\n",
    "    .withColumn(\"CREATED_DATE\", to_date(col('CREATED_DATE'), \"dd-MMM-yy\"))\\\n",
    "    .withColumn(\"MODIFIED_DATE\", to_date(col('MODIFIED_DATE'), \"dd-MMM-yy\"))\n",
    "\n",
    "zipcode.printSchema()\n",
    "zipcode.createOrReplaceTempView(\"zipcode\")\n",
    "zipcode.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ddaeb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      "\n",
      "+-----------+------+------+---------+\n",
      "|EMPLOYEE_ID|  NAME|SALARY|    TITLE|\n",
      "+-----------+------+------+---------+\n",
      "|          1|  John|  1000|  Analyst|\n",
      "|          2|  Mary|  2000|  Manager|\n",
      "|          3|Stella|  5000|President|\n",
      "+-----------+------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"nullValue\", \"\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .csv(\"student/EMPLOYEE_DATA_TABLE.csv\")\n",
    "\n",
    "employee.printSchema()\n",
    "employee.createOrReplaceTempView(\"employee\")\n",
    "employee.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b4e10",
   "metadata": {},
   "source": [
    "---\n",
    "# Group BY and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161398a",
   "metadata": {},
   "source": [
    "## Course prerequisite counts\n",
    "\n",
    "SparkSQL requires explicit assurance that the scalar-subquery returns only one record \n",
    "\n",
    "* [Correlated scalar subqueries must be Aggregated](https://stackoverflow.com/a/46271504/4281353)\n",
    "\n",
    "> when Spark SQL Analyzer/Catalyst can't make 100% sure just by looking at the SQL statement that the sub-query only returns a single row, the exception is thrown.\n",
    "> If you are sure that your subquery only gives a single row you can use one of the following aggregation standard functions, so Spark Analyzer is happy:\n",
    ">\n",
    "> * first\n",
    "> * avg\n",
    "> * max\n",
    "> * min\n",
    "\n",
    "* [SparkSQL - How to make scalar subquery work without FIRST/MIN/MAX/AVG](https://stackoverflow.com/questions/71182919)\n",
    "\n",
    "> Couldn't find first(description) if FIRST is specified in SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "30b77dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+-----------------------------+\n",
      "|prerequisite|cnt|course_name                  |\n",
      "+------------+---+-----------------------------+\n",
      "|10          |1  |Technology Concepts          |\n",
      "|20          |5  |Intro to Information Systems |\n",
      "|25          |2  |Intro to Programming         |\n",
      "|80          |2  |Programming Techniques       |\n",
      "|120         |1  |Intro to Java Programming    |\n",
      "|122         |2  |Intermediate Java Programming|\n",
      "|125         |1  |Java Developer I             |\n",
      "|130         |2  |Intro to Unix                |\n",
      "|132         |1  |Basics of Unix Admin         |\n",
      "|134         |1  |Advanced Unix Admin          |\n",
      "|140         |1  |Systems Analysis             |\n",
      "|204         |1  |Intro to SQL                 |\n",
      "|220         |1  |PL/SQL Programming           |\n",
      "|310         |2  |Operating Systems            |\n",
      "|350         |2  |Java Developer II            |\n",
      "|420         |1  |Database System Principles   |\n",
      "+------------+---+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT \n",
    "    c.*,\n",
    "    (SELECT FIRST(e.description) FROM course e WHERE e.course_no = c.prerequisite) as course_name\n",
    "FROM (\n",
    "    SELECT\n",
    "        prerequisite AS prerequisite,\n",
    "        COUNT(*) as cnt\n",
    "    FROM\n",
    "        course c\n",
    "    WHERE \n",
    "        c.prerequisite IS NOT NULL\n",
    "    GROUP BY \n",
    "        c.prerequisite\n",
    "    ORDER BY\n",
    "        prerequisite\n",
    ") c\n",
    "ORDER BY\n",
    "    prerequisite\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875218b",
   "metadata": {},
   "source": [
    "## Course gade statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ae565d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+------------------+-----+----+\n",
      "|course_no|course_name                  |number_of_students|mean |std |\n",
      "+---------+-----------------------------+------------------+-----+----+\n",
      "|10       |Technology Concepts          |11                |84.27|9.59|\n",
      "|20       |Intro to Information Systems |66                |85.77|8.18|\n",
      "|25       |Intro to Programming         |304               |86.04|7.66|\n",
      "|100      |Hands-On Windows             |128               |87.23|7.81|\n",
      "|120      |Intro to Java Programming    |207               |86.62|7.47|\n",
      "|122      |Intermediate Java Programming|198               |86.86|7.66|\n",
      "|124      |Advanced Java Programming    |80                |84.83|6.89|\n",
      "|125      |Java Developer I             |92                |86.27|8.44|\n",
      "|130      |Intro to Unix                |88                |86.82|8.03|\n",
      "|132      |Basics of Unix Admin         |18                |89.28|9.86|\n",
      "|134      |Advanced Unix Admin          |21                |86.9 |7.42|\n",
      "|135      |Unix Tips and Techniques     |42                |85.05|7.9 |\n",
      "|140      |Systems Analysis             |149               |86.91|7.76|\n",
      "|142      |Project Management           |69                |84.97|7.57|\n",
      "|145      |Internet Protocols           |18                |87.94|5.87|\n",
      "|146      |Java for C/C++ Programmers   |31                |88.19|7.19|\n",
      "|147      |GUI Design Lab               |45                |84.56|7.02|\n",
      "|204      |Intro to SQL                 |9                 |84.78|6.83|\n",
      "|230      |Intro to the Internet        |130               |86.72|7.42|\n",
      "|240      |Intro to the BASIC Language  |119               |86.17|7.68|\n",
      "+---------+-----------------------------+------------------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    s.course_no AS course_no,\n",
    "    c.description as course_name,\n",
    "    COUNT(g.numeric_grade) AS number_of_students, \n",
    "    ROUND(AVG(g.numeric_grade),2) AS mean, \n",
    "    ROUND(STDDEV(g.numeric_grade), 2) AS std\n",
    "FROM \n",
    "    course c\n",
    "    INNER JOIN section s ON s.course_no = c.course_no\n",
    "    INNER JOIN grade g ON g.section_id = s.section_id\n",
    "GROUP BY\n",
    "    s.course_no, c.description\n",
    "ORDER BY\n",
    "    course_no ASC\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff034da",
   "metadata": {},
   "source": [
    "## Student grardes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7c78fb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------+----------------------------+----------+-------------+\n",
      "|student_id|name          |course_no|description                 |section_id|numeric_grade|\n",
      "+----------+--------------+---------+----------------------------+----------+-------------+\n",
      "|128       |Jeff Runyan   |10       |Technology Concepts         |80        |83           |\n",
      "|235       |Michael Carcia|20       |Intro to Information Systems|83        |99           |\n",
      "|235       |Michael Carcia|20       |Intro to Information Systems|83        |90           |\n",
      "|158       |Roy Limate    |20       |Intro to Information Systems|84        |88           |\n",
      "|238       |Roger Snow    |25       |Intro to Programming        |85        |92           |\n",
      "+----------+--------------+---------+----------------------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT DISTINCT\n",
    "    g.student_id,\n",
    "    CONCAT(t.first_name, ' ', t.last_name) AS name,\n",
    "    c.course_no,\n",
    "    c.description,\n",
    "    s.section_id,\n",
    "    g.numeric_grade\n",
    "FROM\n",
    "    course c\n",
    "    INNER JOIN section s ON s.course_no = c.course_no\n",
    "    INNER JOIN grade g ON g.section_id = s.section_id\n",
    "    INNER JOIN student t on g.student_id = t.student_id\n",
    "\"\"\"\n",
    "spark.sql(query).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d3fe2",
   "metadata": {},
   "source": [
    "## Students whose grades are avove course average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "20add6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------+----------------------------+----------+-----+-------+\n",
      "|student_id|name               |course_no|description                 |section_id|grade|average|\n",
      "+----------+-------------------+---------+----------------------------+----------+-----+-------+\n",
      "|128       |Jeff Runyan        |10       |Technology Concepts         |80        |91   |84.27  |\n",
      "|124       |Daniel Wicelinski  |20       |Intro to Information Systems|83        |99   |85.77  |\n",
      "|199       |J. Segall          |20       |Intro to Information Systems|84        |99   |85.77  |\n",
      "|104       |Laetia Enison      |20       |Intro to Information Systems|81        |92   |85.77  |\n",
      "|103       |J. Landry          |20       |Intro to Information Systems|81        |91   |85.77  |\n",
      "|235       |Michael Carcia     |20       |Intro to Information Systems|83        |90   |85.77  |\n",
      "|158       |Roy Limate         |20       |Intro to Information Systems|84        |88   |85.77  |\n",
      "|123       |Pierre Radicola    |25       |Intro to Programming        |87        |99   |86.04  |\n",
      "|224       |M. Diokno          |25       |Intro to Programming        |89        |99   |86.04  |\n",
      "|217       |Jeffrey Citron     |25       |Intro to Programming        |86        |99   |86.04  |\n",
      "|247       |Frank Bunnell      |25       |Intro to Programming        |92        |92   |86.04  |\n",
      "|143       |Gerard Biers       |25       |Intro to Programming        |85        |92   |86.04  |\n",
      "|253       |Walter Boremmann   |25       |Intro to Programming        |89        |92   |86.04  |\n",
      "|256       |Lorrane Velasco    |25       |Intro to Programming        |87        |92   |86.04  |\n",
      "|218       |Eric Da Silva      |25       |Intro to Programming        |90        |92   |86.04  |\n",
      "|102       |Fred Crocitto      |25       |Intro to Programming        |89        |92   |86.04  |\n",
      "|227       |Bessie Heedles     |25       |Intro to Programming        |89        |91   |86.04  |\n",
      "|163       |Nicole Gillen      |25       |Intro to Programming        |92        |91   |86.04  |\n",
      "|118       |Hiedi Lopez        |25       |Intro to Programming        |90        |91   |86.04  |\n",
      "|254       |Melvina Chamnonkool|25       |Intro to Programming        |87        |91   |86.04  |\n",
      "+----------+-------------------+---------+----------------------------+----------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "WITH course_grade_average AS (\n",
    "    SELECT DISTINCT\n",
    "        c.course_no,\n",
    "        AVG(g.numeric_grade) AS grade_average\n",
    "    FROM\n",
    "        course c\n",
    "        INNER JOIN section s ON s.course_no = c.course_no\n",
    "        INNER JOIN grade g ON g.section_id = s.section_id\n",
    "    GROUP BY c.course_no\n",
    "    ORDER BY c.course_no ASC\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "    g.student_id,\n",
    "    CONCAT(t.first_name, ' ', t.last_name) AS name,\n",
    "    c.course_no,\n",
    "    c.description,\n",
    "    s.section_id,\n",
    "    g.numeric_grade as grade,\n",
    "    ROUND(a.grade_average, 2) as average\n",
    "FROM\n",
    "    course c\n",
    "    INNER JOIN section s ON s.course_no = c.course_no\n",
    "    INNER JOIN grade g ON g.section_id = s.section_id\n",
    "    INNER JOIN student t ON g.student_id = t.student_id\n",
    "    INNER JOIN course_grade_average a ON c.course_no = a.course_no\n",
    "WHERE\n",
    "    g.numeric_grade > a.grade_average\n",
    "    AND g.grade_type_code = 'FI'\n",
    "ORDER BY \n",
    "    course_no,\n",
    "    grade DESC\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bf8fb",
   "metadata": {},
   "source": [
    "## Students who enrolled more than two courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "41e0ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|student_id|count(section_id)|\n",
      "+----------+-----------------+\n",
      "|124       |4                |\n",
      "|184       |3                |\n",
      "|214       |4                |\n",
      "|215       |3                |\n",
      "|232       |3                |\n",
      "|238       |3                |\n",
      "|250       |3                |\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    student_id,\n",
    "    COUNT(section_id)\n",
    "FROM \n",
    "    enrollment\n",
    "GROUP BY\n",
    "    student_id\n",
    "HAVING \n",
    "    COUNT(section_id) > 2\n",
    "ORDER BY\n",
    "    student_id\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1928af9",
   "metadata": {},
   "source": [
    "---\n",
    "# Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a09e1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe597fb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "71a6106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11077"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del spark\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
